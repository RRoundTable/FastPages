<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><link rel="shortcut icon" type="image/x-icon" href="/FastPages/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Abstract | fastpages</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Abstract" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="다양한 kernel size의 효과 다양한 kernel size의 조합은 모델의 accuracy 및 efficient를 향상 시킬 수 있다. 위를 바탕으로 depth-wise convolution(MixConv)제안 MixConv의 효과를 증명하기 위해서 AutoML을 결합" />
<meta property="og:description" content="다양한 kernel size의 효과 다양한 kernel size의 조합은 모델의 accuracy 및 efficient를 향상 시킬 수 있다. 위를 바탕으로 depth-wise convolution(MixConv)제안 MixConv의 효과를 증명하기 위해서 AutoML을 결합" />
<link rel="canonical" href="https://rroundtable.github.io/FastPages/2019/08/23/mixconv.html" />
<meta property="og:url" content="https://rroundtable.github.io/FastPages/2019/08/23/mixconv.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-08-23T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2019-08-23T00:00:00-05:00","headline":"Abstract","mainEntityOfPage":{"@type":"WebPage","@id":"https://rroundtable.github.io/FastPages/2019/08/23/mixconv.html"},"description":"다양한 kernel size의 효과 다양한 kernel size의 조합은 모델의 accuracy 및 efficient를 향상 시킬 수 있다. 위를 바탕으로 depth-wise convolution(MixConv)제안 MixConv의 효과를 증명하기 위해서 AutoML을 결합","@type":"BlogPosting","url":"https://rroundtable.github.io/FastPages/2019/08/23/mixconv.html","dateModified":"2019-08-23T00:00:00-05:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  <link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
  <link rel="stylesheet" href="/FastPages/assets/main.css">
  <link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://rroundtable.github.io/FastPages/feed.xml" title="fastpages" />

  <script>
  function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
  }
  window.onload = wrap_img;
  </script>

  <script>
    document.addEventListener("DOMContentLoaded", function(){
      // add link icon to anchor tags
      var elem = document.querySelectorAll(".anchor-link")
      elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
      // remove paragraph tags in rendered toc (happens from notebooks)
      var toctags = document.querySelectorAll(".toc-entry")
      toctags.forEach(e => (e.firstElementChild.innerText = e.firstElementChild.innerText.replace('¶', '')))
    });
  </script>

  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>

</head><body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/FastPages/">fastpages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/FastPages/about/">About Me</a><a class="page-link" href="/FastPages/search/">Search</a><a class="page-link" href="/FastPages/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Abstract</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2019-08-23T00:00:00-05:00" itemprop="datePublished">
        Aug 23, 2019
      </time>
    •<span class="read-time" title="Estimated read time">
    
    
      4 min read
    
</span></p>

    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul>
  <li>다양한 kernel size의 효과
    <ul>
      <li>다양한 kernel size의 조합은 모델의 accuracy 및 efficient를 향상 시킬 수 있다.</li>
    </ul>
  </li>
  <li>위를 바탕으로 depth-wise convolution(MixConv)제안</li>
  <li>MixConv의 효과를 증명하기 위해서 AutoML을 결합</li>
</ul>

<h2 id="introduction">Introduction</h2>

<p><img src="https://user-images.githubusercontent.com/27891090/63566425-13ddee80-c5a8-11e9-8c9f-0bb50224c913.png" style="width: 70%" /></p>

<p>Figure 1에서 볼 수 있듯이, kernel size가 클수록 모델의 성능이 올라간다고 할 수 없다.  올라가는 추세를 보이다가 k9*9를 넘어서면 accuracy가 떨어지는 것을 확인할 수 있다.</p>

<p>ConvNets 연구에서는 하나의 kernel size의 한계를 말한다. 결국 high-resolustion pattern을 위해서는 큰 kernel size가 필요하고 local-resolution pattern을 위해서는 작은 kernel-size가 필요하다.</p>

<p>아래는 해당 논문의 MixConv의 개략적인 구조이다.</p>

<p><img src="https://user-images.githubusercontent.com/27891090/63566675-0b39e800-c5a9-11e9-8fdb-7943cb6fc28d.png" style="width: 70%" /></p>

<h2 id="related-work">Related Work</h2>

<ul>
  <li>
    <p>Efficient ConvNets</p>
  </li>
  <li>
    <p>Multi-Scale Networks and Features</p>

    <ul>
      <li>이전의 연구들은 모델 구조 자체를 변화시킴</li>
      <li>MixConv는 모델의 구조는 그대로 유지한채로 kernel size를 변화시키는 것이 목표</li>
    </ul>
  </li>
  <li>
    <p>Neural Arichitecture Search</p>
  </li>
</ul>

<h2 id="mixconv">MixConv</h2>

<p>MixConv는 하나의 depth wise convolution op에서 multiple kernel을 섞는 것이다. 기대효과는 다양한 타입의 pattern을 수집하는 것이다.</p>

<h3 id="31-mixconv-feature-map">3.1 MixConv Feature Map</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">mixconv</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="o">**</span><span class="n">args</span><span class="p">):</span>
  <span class="c1"># x: input features with shape [N,H,W,C]
</span>  <span class="c1"># filters: a list of filters with shape [K_i, K_i, C_i, M_i] for i−th group.
</span>  <span class="n">G</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">filters</span><span class="p">)</span> <span class="c1"># number of groups.
</span>  <span class="n">y</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">xi</span><span class="p">,</span> <span class="n">fi</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">G</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="err">−</span><span class="mi">1</span><span class="p">),</span> <span class="n">filters</span><span class="p">):</span>
  <span class="n">y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">depthwise_conv2d</span><span class="p">(</span><span class="n">xi</span><span class="p">,</span> <span class="n">fi</span><span class="p">,</span> <span class="err">∗∗</span><span class="n">args</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="err">−</span><span class="mi">1</span><span class="p">)</span>

</code></pre></div></div>

<ul>
  <li>$X^{(h, w, c)}$: input tensor with shape (h, w, c)
    <ul>
      <li>h: height, w: width, c: channel</li>
    </ul>
  </li>
  <li>$W^{(k, k, c, m)}$ : depth wise convolution kernel
    <ul>
      <li>$k \times k$ : kernel size</li>
      <li>$c$: input channel size</li>
      <li>$m$: output channel size</li>
    </ul>
  </li>
  <li>$Y^{(h, w, c*m)}$: same spatial shape (h, w), multiplied output channel size $m \cdot c$</li>
</ul>

<p><code class="language-plaintext highlighter-rouge">$$
Y_{x, y, z} = \sum_{-\frac{k}{2} \le i \le \frac{k}{2}, -\frac{k}{2} \le j \le \frac{k}{2}}
X_{x+i, y+j, \frac{z}{m}} \cdot W_{i, j, z} \
\ \ \forall z=1, \cdots, m \cdot c
$$</code></p>

<p>위의 식은 MixConv과 적용되는 과정을 수식화한 것이다. Input tensor를 g개의 그룹으로 분리하면 아래와 같다.
<code class="language-plaintext highlighter-rouge">$$
&lt;\hat{X}^{(h,w,c_1)}, \cdots, \hat{X}^{(h,w,c_g)}&gt;
$$</code>
각 tensor의 spatial height와 width는 모두 동일하며, 각 channel을 모두 더하면 다음과 같다.
<code class="language-plaintext highlighter-rouge">$$
c_1 + c_2 + \cdots + c_g = c
$$</code>
또한 g개의 kernel group을 구성할 수 있다.
<code class="language-plaintext highlighter-rouge">$$
&lt;\hat{W}^{(k_1,k_1,c_1, m)}, \cdots, \hat{W}^{(k_g,k_g,c_g, m)}&gt;
$$</code>
t-th group output은 다음과 같이 구성된다.
<code class="language-plaintext highlighter-rouge">$$
\hat{Y^t}_{x, y, z} = \sum_{-\frac{k_t}{2} \le i \le \frac{k_t}{2}, -\frac{k_t}{2} \le j \le \frac{k_t}{2}} \hat{X^t}_{x+i, y+i, \frac{z}{m}} \cdot\hat{W^t}_{i, j, z} \
\ \ \forall z=1, \cdots, m \cdot c_t
$$</code>
그리고 final output tensor는 아래와 같다.
<code class="language-plaintext highlighter-rouge">$$
Y_{x, y, z_0}=Concat(\hat{Y^1}_{x,y,z_1}, \cdots,\hat{Y^g}_{x,y,z_g})
$$</code></p>

<h3 id="32-mixconv-design-choices">3.2 MixConv Design Choices</h3>

<ul>
  <li>
    <p>Group size</p>

    <p>하나의 input tensor에 얼마나 다양한 size의 kernel을 사용할 것인지 정해야 한다.</p>

    <p>group이 하나라면 vanilla depth wise convolution과 같고, 해당 논문은 실험을 통해서 MobileNets에서는 $g=4$ 가 안정적으로 적용됨을 확인하였다. 하지만, neural architecture search를 통해서 group size가 1에서 5까지의 범위에서 변하면 더 좋은 성능을 낼 수 있음을 확인하였다.</p>
  </li>
  <li>
    <p>Kenel size per group</p>

    <p>다른 그룹간의 같은 kernel size을 사용한다면, 그룹을 분리하는 의미가 없다. 따라서 해당 논문에서는 다른 그룹은 다른 kernel size를 가지도록 제한하였다.</p>
  </li>
  <li>
    <p>channel size per group</p>

    <p>해당 논문에서는 두 가지 channel 분리 방법을 사용하였다.</p>

    <ol>
      <li>equal parition: (8, 8, 8, 8)</li>
      <li>exponential parition: (16, 8, 4, 4)</li>
    </ol>
  </li>
  <li>
    <p>dilated convolution</p>

    <p>large size의 kernel은 많은 parameter와 computation을 필요로 한다. 따라서 이를 대처하기 위해서 dilated convolution을 사용하였다.</p>

    <blockquote>
      <p>[Dilated convolution]</p>

      <p>Dilated Convolution은 필터 내부에 zero padding을 추가해 강제로 receptive field를 늘리는 방법이다. 위 그림은 파란색이 인풋, 초록색이 아웃풋인데, 진한 파랑 부분에만 weight가 있고 나머지 부분은 0으로 채워진다.</p>

      <p>출처: https://3months.tistory.com/213 [Deep Play]</p>

      <p><img src="https://t1.daumcdn.net/cfile/tistory/99448C335A014DD609" style="width: 30%" /></p>
    </blockquote>
  </li>
</ul>

<h3 id="33-mixconv-performance-on-mobile-nets">3.3 MixConv Performance on Mobile Nets</h3>

<p><img src="https://user-images.githubusercontent.com/27891090/63569061-b7340100-c5b2-11e9-9610-8f1fc18b48ae.png" style="width: 70%" /></p>

<p><img src="https://user-images.githubusercontent.com/27891090/63568374-fca2ff00-c5af-11e9-9894-f19c51bec874.png" style="width: 70%" /></p>

<h3 id="3-4-ablation-study">3. 4 Ablation Study</h3>

<blockquote>
  <p>ablation study</p>

  <p>모델이나 알고리즘의 특징들을 제거하면서 그게 퍼포먼스에 어떤 영향을 줄지 연구하는 거</p>
</blockquote>

<ul>
  <li>MixConv for Single Layer</li>
</ul>

<p><img src="https://user-images.githubusercontent.com/27891090/63568354-e5fca800-c5af-11e9-8add-abd49321aaf2.png" style="width: 70%" /></p>

<p>​	하나의 layer씩 변화시켜본 결과는 위의 Figure 5와 같다. 2(s2)-(with large kernel size + stride2)를 보면 accuracy가 상승한 것을 확인할 수 있으며, 대부분의 레이어에서  비슷하거나 조금의 성능 향상이 있었다.</p>

<ul>
  <li>
    <p>Channel Partition Method/ Dilated Convolution</p>

    <p><img src="https://user-images.githubusercontent.com/27891090/63569248-97e9a380-c5b3-11e9-9382-80a0f4bdff64.png" style="width: 70%" /></p>
  </li>
</ul>

<p>Figure 6에서 확인할 수 있듯이, dilated convolution은 parameter size가 커질 때 급격한 성능 하락이 있다. 해당 논문은 이는 local information을 잃어버리기 때문이라고 주장한다.</p>

<blockquote>
  <p>FLOPS</p>

  <p><strong>플롭스</strong>(<strong>FLOPS</strong>, <strong>FL</strong>oating point <strong>OP</strong>erations per <strong>S</strong>econd)는 <a href="https://ko.wikipedia.org/wiki/컴퓨터">컴퓨터</a>의 성능을 수치로 나타낼 때 주로 사용되는 <a href="https://ko.wikipedia.org/wiki/단위">단위</a>이다.</p>

  <p><a href="https://ko.wikipedia.org/wiki/플롭스">https://ko.wikipedia.org/wiki/%ED%94%8C%EB%A1%AD%EC%8A%A4</a></p>
</blockquote>

<h2 id="mixnet">MixNet</h2>

<h3 id="41-architecture-search">4.1 Architecture Search</h3>

<p>이전의 Architecture Search 연구에서는 kernel size, expansion ratio, channel size등을 고려했다면, 해당 논문에서는 vanilla depth wise convolution을 baseline으로 삼고 MixConv를 search option으로 지정하였다.</p>

<ul>
  <li>MixConv 옵션으로는 $g=1, \cdots, 5$ 가 있다.</li>
  <li>search option을 단순화 시키기 위해서 exponential partion은 제외</li>
</ul>

<h3 id="42-mixnet-performance-on-imagenet">4.2 MixNet Performance on ImageNet</h3>

<p><img src="https://user-images.githubusercontent.com/27891090/63569698-6d004f00-c5b5-11e9-97ea-1dfa879bda33.png" style="width: 70%" /></p>

<p><img src="https://user-images.githubusercontent.com/27891090/63569603-0418d700-c5b5-11e9-8358-31d30f1a65e4.png" style="width: 70%" /></p>

<h3 id="43-mixnet-architectures">4.3 MixNet Architectures</h3>

<p>accuracy와 efficiency 향상의 이유를 알기 위해서 network architecture를 분석하였다.</p>

<p>전반적으로 MixNet모델들은 다양한 크기의 kernel을 사용하였다.</p>

<ul>
  <li>small kernel은 앞단의 stage에서 computation cost를 줄이기 위하여 사용함</li>
  <li>large kernel은 뒷단의 stage에서 더 좋은 accuracy를 위해서 많이 나타남.</li>
</ul>

<p><img src="https://user-images.githubusercontent.com/27891090/63569643-332f4880-c5b5-11e9-9ec8-a564342c1efd.png" style="70%" /></p>

<p>또한, 큰 MixNet model일수록 parameter와 FLOPS를 비용으로 지불하면서 더 큰 size의 kernel을 많이 사용하고 더 많은 수의 layer를 사용하였다.</p>

<p>Figure 1을 보면 vanilla depthwise convolution은 일정크기 이상의 kernel을 사용하면 급격한 성능하락이 있었지만, MixConv는 large size의 kernel을 사용할 수 있었다.</p>

<h3 id="44-transfer-learning-performance">4.4 Transfer Learning Performance</h3>

<p><img src="https://user-images.githubusercontent.com/27891090/63570033-b1401f00-c5b6-11e9-99db-95aea0bfd8d4.png" style="70%" /></p>

<p>Figure 9는 transfer learning을 MixNet에 적용하였을 때, 성능향상을 나타내는 이미지이다. MixNet-M은 97.92%의 성능향상을 했으며 이는 ResNet-50보다 1% 높은 수치이다.</p>

<p>실험은 imagenet으로 pretrained된 모델을 CIFAR10, 100에 적용한 것이다.</p>

<h4 id="reference">Reference</h4>

<ul>
  <li>https://arxiv.org/pdf/1907.09595.pdf</li>
</ul>

  </div><a class="u-url" href="/FastPages/2019/08/23/mixconv.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/FastPages/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">fastpages</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">fastpages</li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list">
  <li><a href="https://github.com/RRoundTable"><svg class="social svg-icon"><use xlink:href="/FastPages/assets/minima-social-icons.svg#github"></use></svg> <span class="username">RRoundTable</span></a></li><li><a href="https://www.twitter.com/fastdotai"><svg class="social svg-icon"><use xlink:href="/FastPages/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">fastdotai</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
