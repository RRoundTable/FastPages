<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="https://rroundtable.github.io/FastPages/feed.xml" rel="self" type="application/atom+xml" /><link href="https://rroundtable.github.io/FastPages/" rel="alternate" type="text/html" /><updated>2020-03-21T04:32:36-05:00</updated><id>https://rroundtable.github.io/FastPages/feed.xml</id><title type="html">RoundTable</title><subtitle>Tech Blog for RoundTable</subtitle><entry><title type="html">Missing Semester 정리글</title><link href="https://rroundtable.github.io/FastPages/shell/bash/2020/03/05/missing-semeste-%EC%A0%95%EB%A6%AC%EA%B8%80.html" rel="alternate" type="text/html" title="Missing Semester 정리글" /><published>2020-03-05T00:00:00-06:00</published><updated>2020-03-05T00:00:00-06:00</updated><id>https://rroundtable.github.io/FastPages/shell/bash/2020/03/05/missing-semeste-%EC%A0%95%EB%A6%AC%EA%B8%80</id><content type="html" xml:base="https://rroundtable.github.io/FastPages/shell/bash/2020/03/05/missing-semeste-%EC%A0%95%EB%A6%AC%EA%B8%80.html">&lt;h2 id=&quot;1-shell&quot;&gt;1. Shell&lt;/h2&gt;

&lt;p&gt;리눅스의 쉘은 명령어와 프로그램을 실행할 때 사용하는 인터페이스이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/FastPages/images/2020-03-05-missing-semeste-정리글/shell.png&quot; alt=&quot;&quot; title=&quot;Shell&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;echo&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;리눅스 명령어 echo는 주어진 문자열을, 문자열 사이에 포함된 공백과 줄 마지막에 개행문자를 포함하여 표준출력으로 출력하는 명령어다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;echo &quot;Hellow Wolrd&quot;
&amp;gt;&amp;gt;&amp;gt; Hellow World

echo Hellow\ Wolrd
&amp;gt;&amp;gt;&amp;gt; Hellow World

echo $HOME
&amp;gt;&amp;gt;&amp;gt; /root

echo $PATH
&amp;gt;&amp;gt;&amp;gt; $PATH에 포함된 주소들을 출력

which echo
&amp;gt;&amp;gt;&amp;gt; /usr/bin/echo # 사용하고 있는 echo 위치 출력

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;pwd&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pwd
&amp;gt;&amp;gt;&amp;gt; /home # present working directory
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;cd&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /roundtable # change directory
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;. (dot) / .. (dot dot)&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;.. # parent directory
cd .. # /home/roundtable -&amp;gt; /home

. # current directory
cd ./roundtable # /home -&amp;gt; /home/roundtable
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;ls&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ls
&amp;gt;&amp;gt;&amp;gt; print all files in the current directory
ls -help
&amp;gt;&amp;gt;&amp;gt; 다양한 옵션에 대한 정보를 받아볼 수 있음
ls -l
&amp;gt;&amp;gt;&amp;gt; 파일에 대한 추가적인 정보를 얻을 수 있음
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;~&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd ~ # home directory
cd ~/roundtable # cd /home/roundtable
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;cd -&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd - # back to parent directory
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;mv&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mv &amp;lt;current_file&amp;gt; &amp;lt;new_file&amp;gt; # rename the file or move the file in dirrent directory
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;cp&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cp &amp;lt;current_file&amp;gt; &amp;lt;new_file&amp;gt; # copy
cp -r &amp;lt;current folder&amp;gt; &amp;lt;new_folder&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;rm&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rm &amp;lt;current_file&amp;gt; # remove
rmdir &amp;lt;folder&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;mkdir&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mkdir &amp;lt;new directory name&amp;gt; # make directory
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;man&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;man ls # manual page for ls
# if you want to quik, press q
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;ctrl + l&lt;/strong&gt;: clear the terminal&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Angle bracket signs&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;input stream, output stream이 존재한다. 이를 적절히 조절할 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# &amp;lt; file 
# &amp;gt; file

echo hello &amp;gt; hello.txt # hello(print)가 hello.txt의 입력으로 들어간다.
cat hello.txt
&amp;gt;&amp;gt;&amp;gt; hello

cat &amp;lt; hello.txt &amp;gt; hello2.txt
cat hello2.txt
&amp;gt;&amp;gt;&amp;gt; hello
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;**&lt;/td&gt;
      &lt;td&gt;(pipe)**&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# file1 | file2 # make output of file1 input of file2
# tail # 마지막 line만 출력해준다.

ls -l / tail -n1
&amp;gt;&amp;gt;&amp;gt; drwxrwxr-x 11 ubuntu ubuntu 4096 Mar  4 12:55 dev # print last line

curl --head --silent google.com | grep -i content-length
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;tail&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;마지막 line만 출력해준다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;curl&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl --head --silent google.com | grep -i content-length
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;sudo: root permission&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo find -L /sys/class/backlight -maxdepth 2 -name '*brightness*'
&amp;gt;&amp;gt;&amp;gt; /sys/class/backlight/thinkpad_screen/brightness

cd /sys/class/backlight/thinkpad_screen

sudo echo 3 &amp;gt; brightness

&amp;gt;&amp;gt;&amp;gt; An error occurred while redirecting file 'brightness'
open: Permission denied


echo 3 | sudo tee brightness
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;cat&lt;/strong&gt;: concatenate&lt;/p&gt;

&lt;p&gt;파일의 내용을 출력&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cat file1
# file1의 내용 출력

cat file1 file2 file3
# file1, file2, file3 이어서 출력

cat &amp;gt; file1 # (내용을 입력하고 ctrl + d를 눌러 저장한다.) 기존 내용을 지우고
cat &amp;gt;&amp;gt; file1 # (내용을 입력하고 ctrl + d를 눌러 저장한다.) 기존의 내용에 이어서

cat file1 file2 &amp;gt; file3 # file1 + file2 = file3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;cd /sys&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /sys # to access various kernel parameters

total 0
drwxr-xr-x   2 root root  0 Mar  5 08:03 block
drwxr-xr-x  47 root root  0 Mar  3 06:53 bus
drwxr-xr-x  69 root root  0 Mar  3 06:51 class
drwxr-xr-x   4 root root  0 Mar  5 08:03 dev
drwxr-xr-x  71 root root  0 Mar  3 04:43 devices
drwxrwxrwt   2 root root 40 Mar  3 04:43 firmware
drwxr-xr-x  12 root root  0 Mar  3 04:43 fs
drwxr-xr-x   2 root root  0 Mar  5 08:03 hypervisor
drwxr-xr-x  14 root root  0 Mar  5 08:03 kernel
drwxr-xr-x 219 root root  0 Mar  5 08:03 module
drwxr-xr-x   2 root root  0 Mar  5 08:03 power
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;shell은 단순한 argument가 아니라 일종의 프로그래밍이라고 볼 수 있다. 예를 들어서 조건문이나 반복문같은 설정을 할 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;2-shell-tools-and-scripting&quot;&gt;2. Shell Tools and Scripting&lt;/h2&gt;

&lt;p&gt;’’ 하고 “” 는 유사해보이지만, 서로 다르다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;foo=bar
echo &quot;$foo&quot;
# prints bar
echo '$foo'
# prints $foo

echo &quot;Value is $foo&quot;
# prints 'Value is foo'

echo 'Value is $foo'
# prints 'Value is $foo'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;bash는  if, case, while, for와 같은 구문을 제공한다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mcd (){
	mkdir -p &quot;$1&quot;
	cd &quot;$1&quot;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/home: vim mcd.sh
/home: source mcd.sh
/home: mcd.sh test

/home/test:  # /home -&amp;gt; mkdir /home/test -&amp;gt; cd /home/test
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;$0 - Name of the script&lt;/li&gt;
  &lt;li&gt;$1 to $9 - Arguments to the script. $1 is the first argument and so on.&lt;/li&gt;
  &lt;li&gt;$@ - All the arguments&lt;/li&gt;
  &lt;li&gt;$# - Number of arguments&lt;/li&gt;
  &lt;li&gt;$? - Return code of the previous command&lt;/li&gt;
  &lt;li&gt;$$ - Process Identification number for the current script&lt;/li&gt;
  &lt;li&gt;!! - Entire last command, including arguments. A common pattern is to execute a command only for it to fail due to missing permissions, then you can quickly execute it with sudo by doing sudo !!&lt;/li&gt;
  &lt;li&gt;$_ - Last argument from the last command. If you are in an interactive shell, you can also quickly get this value by typing Esc followed by .&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;echo &quot;Hello&quot;
&amp;gt;&amp;gt;&amp;gt; Hello

echo $?
&amp;gt;&amp;gt;&amp;gt; 0 # No Error

grep foobar mcd.sh
echo $?
&amp;gt;&amp;gt;&amp;gt; 1 # Error
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# || or
false || echo &quot;Oops, fail&quot; 
# Oops, fail


true || echo &quot;Will not be printed&quot;
#

# &amp;amp;&amp;amp; and
true &amp;amp;&amp;amp; echo &quot;Things went well&quot;
# Things went well

false &amp;amp;&amp;amp; echo &quot;Will not be printed&quot;
#

false ; echo &quot;This will always run&quot;
# This will always run
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#!/bin/bash

echo &quot;Starting program at $(date)&quot; # Date will be substituted

echo &quot;Running program $0 with $# arguments with pid $$&quot;

for file in $@; do
    grep foobar $file &amp;gt; /dev/null 2&amp;gt; /dev/null
    # When pattern is not found, grep has exit status 1
    # We redirect STDOUT and STDERR to a null register since we do not care about them
    if [[ $? -ne 0 ]]; then
        echo &quot;File $file does not have any foobar, adding one&quot;
        echo &quot;# foobar&quot; &amp;gt;&amp;gt; &quot;$file&quot;
    fi
done
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;?&lt;/strong&gt; : one of character
***** : any amount of characters&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
convert image.{png,jpg}
# Will expand to
convert image.png image.jpg

cp /path/to/project/{foo,bar,baz}.sh /newpath
# Will expand to
cp /path/to/project/foo.sh /path/to/project/bar.sh /path/to/project/baz.sh /newpath

# Globbing techniques can also be combined
mv *{.py,.sh} folder
# Will move all *.py and *.sh files


mkdir foo bar
# This creates files foo/a, foo/b, ... foo/h, bar/a, bar/b, ... bar/h
touch {foo,bar}/{a..j}
touch foo/x bar/y
# Show differences between files in foo and bar
diff &amp;lt;(ls foo) &amp;lt;(ls bar)
# Outputs
# &amp;lt; x
# ---
# &amp;gt; y
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;in python&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Shebang&lt;/strong&gt;은 (사전에 검색해보면) 쉬뱅이라고 읽습니다. 쉬뱅은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;#!&lt;/code&gt;로 시작하는 문자열이며 스크립트의 맨 첫번째 라인에 있습니다. 쉬뱅은 유닉스 계열 운영체제에서 스크립트가 실행될 때, 파이썬, 배쉬쉘 등 어떤 인터프리터에 의해서 동작이 되는지 알려줍니다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#!/usr/local/bin/python
import sys
for arg in reversed(sys.argv[1:]):
    print(arg)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;shellcheck&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ shellcheck test.sh

In test.sh line 2:
T0=`date +%s`
   ^-- SC2006: Use $(..) instead of legacy `..`.

In test.sh line 4:
T1=`date +%s`
   ^-- SC2006: Use $(..) instead of legacy `..`.

In test.sh line 5:
ELAPSED_TIME=$((T1-T0))
^-- SC2034: ELAPSED_TIME appears unused. Verify it or export it.

In test.sh line 7:
echo &quot;START_TIME: &quot; ${T0}
                    ^-- SC2086: Double quote to prevent globbing and word splitting.

In test.sh line 8:
echo &quot;END_TIME: &quot; ${T1}
                  ^-- SC2086: Double quote to prevent globbing and word splitting.

In test.sh line 9:
echo &quot;ELAPSED_TIME: ${ELAPSES_TIME} sec&quot;
                    ^-- SC2153: Possible misspelling: ELAPSES_TIME may not be assigned, but ELAPSED_TIME is.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;export&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;환경변수를 저장하는 역할, 터미널이 꺼지면 사라진다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vi ~/.bashrc # 해당 주소에서 작업을 하게되면 영구적으로 남는다.

export water=&quot;삼다수&quot;
export TEMP_DIR=/tmp
export BASE_DIR=$TEMP_DIR/backup
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# gpu idx를 지정할 때 사용할 수도 있다.

export CUDA_VISIBLE_DEVICES = 1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Finding how to use commands&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ls -h
ls --help

man ls
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;manpage&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://tldr.sh/&quot;&gt;TLDR pages&lt;/a&gt;: 간단하게 찾아볼 수 있음&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Finding files&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Find all directories named src
find . -name src -type d
# Find all python files that have a folder named test in their path
find . -path '**/test/**/*.py' -type f
# Find all files modified in the last day
find . -mtime -1
# Find all zip files with size in range 500k to 10M
find . -size +500k -size -10M -name '*.tar.gz'

# Delete all files with .tmp extension
find . -name '*.tmp' -exec rm {} \;
# Find all PNG files and convert them to JPG
find . -name '*.png' -exec convert {} {.}.jpg \;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Finding code&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://man7.org/linux/man-pages/man1/grep.1.html&quot;&gt;&lt;strong&gt;grep&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;grep foobar mcd.sh
grep -R foobar . # source code 검색도 가능
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/BurntSushi/ripgrep&quot;&gt;&lt;strong&gt;ripgrep&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Find all python files where I used the requests library
rg -t py 'import requests'
# Find all files (including hidden files) without a shebang line
rg -u --files-without-match &quot;^#!&quot;
# Find all matches of foo and print the following 5 lines
rg foo -A 5
# Print statistics of matches (# of matched lines and files )
rg --stats PATTERN
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Finding shell commands&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;history&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;history

 1 cd .\OneDrive\sourceCode\CPPS\
 2 cd ..
 3 cd .\EEN-with-Keras\

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Ctrl + R&lt;/strong&gt; : history 추적, 유용&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;zsh&lt;/strong&gt;: 유용한 bash 도구&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Directory Naviation&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ls -R&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://linux.die.net/man/1/tree&quot;&gt;tree&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/Canop/broot&quot;&gt;broot&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;nnn&lt;/li&gt;
  &lt;li&gt;ranger&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ls -R
tree 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Reference: https://missing.csail.mit.edu/2020/?fbclid=IwAR2gQe5LToKuqVUwbfegqSOk6BnIqscbnqjK0e3js64EceMswNqW0KgeSEo&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. Shell</summary></entry><entry><title type="html">Fastpages Notebook Blog Post</title><link href="https://rroundtable.github.io/FastPages/fastpages/jupyter/2020/02/20/test.html" rel="alternate" type="text/html" title="Fastpages Notebook Blog Post" /><published>2020-02-20T00:00:00-06:00</published><updated>2020-02-20T00:00:00-06:00</updated><id>https://rroundtable.github.io/FastPages/fastpages/jupyter/2020/02/20/test</id><content type="html" xml:base="https://rroundtable.github.io/FastPages/fastpages/jupyter/2020/02/20/test.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-02-20-test.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;About&quot;&gt;About&lt;a class=&quot;anchor-link&quot; href=&quot;#About&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;This notebook is a demonstration of some of capabilities of &lt;a href=&quot;https://github.com/fastai/fastpages&quot;&gt;fastpages&lt;/a&gt; with notebooks.&lt;/p&gt;
&lt;p&gt;With &lt;code&gt;fastpages&lt;/code&gt; you can save your jupyter notebooks into the &lt;code&gt;_notebooks&lt;/code&gt; folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts!&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Front-Matter&quot;&gt;Front Matter&lt;a class=&quot;anchor-link&quot; href=&quot;#Front-Matter&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Front Matter is a markdown cell at the beginning of your notebook that allows you to inject metadata into your notebook. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Setting &lt;code&gt;toc: true&lt;/code&gt; will automatically generate a table of contents&lt;/li&gt;
&lt;li&gt;Setting &lt;code&gt;badges: true&lt;/code&gt; will automatically include GitHub and Google Colab links to your notebook.&lt;/li&gt;
&lt;li&gt;Setting &lt;code&gt;comments: true&lt;/code&gt; will enable commenting on your blog post, powered by &lt;a href=&quot;https://github.com/utterance/utterances&quot;&gt;utterances&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;More details and options for front matter can be viewed on the &lt;a href=&quot;https://github.com/fastai/fastpages#front-matter-related-options&quot;&gt;front matter section&lt;/a&gt; of the README.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Markdown-Shortcuts&quot;&gt;Markdown Shortcuts&lt;a class=&quot;anchor-link&quot; href=&quot;#Markdown-Shortcuts&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;put a &lt;code&gt;#hide&lt;/code&gt; flag at the top of any cell you want to completely hide in the docs&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;put a &lt;code&gt;#collapse&lt;/code&gt; flag at the top of any cell if you want to hide that cell by default, but stil have it be visible to the reader:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;altair&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;alt&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;put a &lt;code&gt;#collapse_show&lt;/code&gt; flag at the top of any cell if you want to &lt;strong&gt;show&lt;/strong&gt; that cell by default, but give the reader the option to hide it:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot; open=&quot;&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse_show&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cars&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;https://vega.github.io/vega-datasets/data/cars.json&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;https://vega.github.io/vega-datasets/data/movies.json&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sp500&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;https://vega.github.io/vega-datasets/data/sp500.csv&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;stocks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;https://vega.github.io/vega-datasets/data/stocks.csv&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;flights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;https://vega.github.io/vega-datasets/data/flights-5k.json&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Interactive-Charts-With-Altair&quot;&gt;Interactive Charts With Altair&lt;a class=&quot;anchor-link&quot; href=&quot;#Interactive-Charts-With-Altair&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Charts made with Altair remain interactive.  Example charts taken from &lt;a href=&quot;https://github.com/uwdata/visualization-curriculum&quot;&gt;this repo&lt;/a&gt;, specifically &lt;a href=&quot;https://github.com/uwdata/visualization-curriculum/blob/master/altair_interaction.ipynb&quot;&gt;this notebook&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Example-1:-DropDown&quot;&gt;Example 1: DropDown&lt;a class=&quot;anchor-link&quot; href=&quot;#Example-1:-DropDown&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# single-value selection over [Major_Genre, MPAA_Rating] pairs&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# use specific hard-wired values as the initial selected values&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;selection&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;selection_single&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Select&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Major_Genre&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;MPAA_Rating&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Major_Genre&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;Drama&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;MPAA_Rating&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;R&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;bind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Major_Genre&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;binding_select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;genres&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;MPAA_Rating&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;binding_radio&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mpaa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  
&lt;span class=&quot;c1&quot;&gt;# scatter plot, modify opacity based on selection&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Chart&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_circle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_selection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;selection&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Rotten_Tomatoes_Rating:Q&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;IMDB_Rating:Q&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tooltip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Title:N&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;opacity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;selection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;

&lt;div id=&quot;altair-viz-1a49e83878ce4d678d7b162f3d6b510f&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
  (function(spec, embedOpt){
    const outputDiv = document.getElementById(&quot;altair-viz-1a49e83878ce4d678d7b162f3d6b510f&quot;);
    const paths = {
      &quot;vega&quot;: &quot;https://cdn.jsdelivr.net/npm//vega@5?noext&quot;,
      &quot;vega-lib&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-lib?noext&quot;,
      &quot;vega-lite&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext&quot;,
      &quot;vega-embed&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-embed@6?noext&quot;,
    };

    function loadScript(lib) {
      return new Promise(function(resolve, reject) {
        var s = document.createElement('script');
        s.src = paths[lib];
        s.async = true;
        s.onload = () =&gt; resolve(paths[lib]);
        s.onerror = () =&gt; reject(`Error loading script: ${paths[lib]}`);
        document.getElementsByTagName(&quot;head&quot;)[0].appendChild(s);
      });
    }

    function showError(err) {
      outputDiv.innerHTML = `&lt;div class=&quot;error&quot; style=&quot;color:red;&quot;&gt;${err}&lt;/div&gt;`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err =&gt; showError(`Javascript Error: ${err.message}&lt;br&gt;This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === &quot;function&quot; &amp;&amp; define.amd) {
      requirejs.config({paths});
      require([&quot;vega-embed&quot;], displayChart, err =&gt; showError(`Error loading script: ${err.message}`));
    } else if (typeof vegaEmbed === &quot;function&quot;) {
      displayChart(vegaEmbed);
    } else {
      loadScript(&quot;vega&quot;)
        .then(() =&gt; loadScript(&quot;vega-lite&quot;))
        .then(() =&gt; loadScript(&quot;vega-embed&quot;))
        .catch(showError)
        .then(() =&gt; displayChart(vegaEmbed));
    }
  })({&quot;config&quot;: {&quot;view&quot;: {&quot;continuousWidth&quot;: 400, &quot;continuousHeight&quot;: 300}}, &quot;data&quot;: {&quot;url&quot;: &quot;https://vega.github.io/vega-datasets/data/movies.json&quot;}, &quot;mark&quot;: &quot;circle&quot;, &quot;encoding&quot;: {&quot;opacity&quot;: {&quot;condition&quot;: {&quot;value&quot;: 0.75, &quot;selection&quot;: &quot;Select&quot;}, &quot;value&quot;: 0.05}, &quot;tooltip&quot;: {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Title&quot;}, &quot;x&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;Rotten_Tomatoes_Rating&quot;}, &quot;y&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;IMDB_Rating&quot;}}, &quot;selection&quot;: {&quot;Select&quot;: {&quot;type&quot;: &quot;single&quot;, &quot;fields&quot;: [&quot;Major_Genre&quot;, &quot;MPAA_Rating&quot;], &quot;init&quot;: {&quot;Major_Genre&quot;: &quot;Drama&quot;, &quot;MPAA_Rating&quot;: &quot;R&quot;}, &quot;bind&quot;: {&quot;Major_Genre&quot;: {&quot;input&quot;: &quot;select&quot;, &quot;options&quot;: [&quot;Action&quot;, &quot;Adventure&quot;, &quot;Black Comedy&quot;, &quot;Comedy&quot;, &quot;Concert/Performance&quot;, &quot;Documentary&quot;, &quot;Drama&quot;, &quot;Horror&quot;, &quot;Musical&quot;, &quot;Romantic Comedy&quot;, &quot;Thriller/Suspense&quot;, &quot;Western&quot;]}, &quot;MPAA_Rating&quot;: {&quot;input&quot;: &quot;radio&quot;, &quot;options&quot;: [&quot;G&quot;, &quot;PG&quot;, &quot;PG-13&quot;, &quot;R&quot;, &quot;NC-17&quot;, &quot;Not Rated&quot;]}}}}, &quot;$schema&quot;: &quot;https://vega.github.io/schema/vega-lite/v4.0.2.json&quot;}, {&quot;mode&quot;: &quot;vega-lite&quot;});
&lt;/script&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Example-2:-Tooltips&quot;&gt;Example 2: Tooltips&lt;a class=&quot;anchor-link&quot; href=&quot;#Example-2:-Tooltips&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Chart&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_circle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_selection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;selection_interval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;scales&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encodings&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;x&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Rotten_Tomatoes_Rating:Q&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;IMDB_Rating:Q&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Axis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minExtent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# use min extent to stabilize axis title placement&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tooltip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Title:N&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;Release_Date:N&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;IMDB_Rating:Q&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;Rotten_Tomatoes_Rating:Q&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;properties&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;600&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;

&lt;div id=&quot;altair-viz-c022b476f4fb482ca6f609bf6ed082d2&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
  (function(spec, embedOpt){
    const outputDiv = document.getElementById(&quot;altair-viz-c022b476f4fb482ca6f609bf6ed082d2&quot;);
    const paths = {
      &quot;vega&quot;: &quot;https://cdn.jsdelivr.net/npm//vega@5?noext&quot;,
      &quot;vega-lib&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-lib?noext&quot;,
      &quot;vega-lite&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext&quot;,
      &quot;vega-embed&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-embed@6?noext&quot;,
    };

    function loadScript(lib) {
      return new Promise(function(resolve, reject) {
        var s = document.createElement('script');
        s.src = paths[lib];
        s.async = true;
        s.onload = () =&gt; resolve(paths[lib]);
        s.onerror = () =&gt; reject(`Error loading script: ${paths[lib]}`);
        document.getElementsByTagName(&quot;head&quot;)[0].appendChild(s);
      });
    }

    function showError(err) {
      outputDiv.innerHTML = `&lt;div class=&quot;error&quot; style=&quot;color:red;&quot;&gt;${err}&lt;/div&gt;`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err =&gt; showError(`Javascript Error: ${err.message}&lt;br&gt;This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === &quot;function&quot; &amp;&amp; define.amd) {
      requirejs.config({paths});
      require([&quot;vega-embed&quot;], displayChart, err =&gt; showError(`Error loading script: ${err.message}`));
    } else if (typeof vegaEmbed === &quot;function&quot;) {
      displayChart(vegaEmbed);
    } else {
      loadScript(&quot;vega&quot;)
        .then(() =&gt; loadScript(&quot;vega-lite&quot;))
        .then(() =&gt; loadScript(&quot;vega-embed&quot;))
        .catch(showError)
        .then(() =&gt; displayChart(vegaEmbed));
    }
  })({&quot;config&quot;: {&quot;view&quot;: {&quot;continuousWidth&quot;: 400, &quot;continuousHeight&quot;: 300}}, &quot;data&quot;: {&quot;url&quot;: &quot;https://vega.github.io/vega-datasets/data/movies.json&quot;}, &quot;mark&quot;: &quot;circle&quot;, &quot;encoding&quot;: {&quot;tooltip&quot;: [{&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Title&quot;}, {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Release_Date&quot;}, {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;IMDB_Rating&quot;}, {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;Rotten_Tomatoes_Rating&quot;}], &quot;x&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;Rotten_Tomatoes_Rating&quot;}, &quot;y&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;axis&quot;: {&quot;minExtent&quot;: 30}, &quot;field&quot;: &quot;IMDB_Rating&quot;}}, &quot;height&quot;: 400, &quot;selection&quot;: {&quot;selector001&quot;: {&quot;type&quot;: &quot;interval&quot;, &quot;bind&quot;: &quot;scales&quot;, &quot;encodings&quot;: [&quot;x&quot;]}}, &quot;width&quot;: 600, &quot;$schema&quot;: &quot;https://vega.github.io/schema/vega-lite/v4.0.2.json&quot;}, {&quot;mode&quot;: &quot;vega-lite&quot;});
&lt;/script&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Example-3:-More-Tooltips&quot;&gt;Example 3: More Tooltips&lt;a class=&quot;anchor-link&quot; href=&quot;#Example-3:-More-Tooltips&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# select a point for which to provide details-on-demand&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;selection_single&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;encodings&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;x&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# limit selection to x-axis value&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;mouseover&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# select on mouseover events&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nearest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# select data point nearest the cursor&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;none&amp;#39;&lt;/span&gt;     &lt;span class=&quot;c1&quot;&gt;# empty selection includes no data points&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# define our base line chart of stock prices&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Chart&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;date:T&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;price:Q&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Scale&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;log&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Color&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;symbol:N&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# base line chart&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# add a rule mark to serve as a guide line&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Chart&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_rule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;#aaa&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;date:T&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# add circle marks for selected time points, hide unselected points&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_circle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;opacity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_selection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# add white stroked text to provide a legible background for labels&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;align&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;left&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stroke&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;white&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strokeWidth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;price:Q&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# add text labels for stock prices&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;align&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;left&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;price:Q&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stocks&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;properties&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;700&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;

&lt;div id=&quot;altair-viz-9283d3681fd24aafa3d1e2f9ad193ecf&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
  (function(spec, embedOpt){
    const outputDiv = document.getElementById(&quot;altair-viz-9283d3681fd24aafa3d1e2f9ad193ecf&quot;);
    const paths = {
      &quot;vega&quot;: &quot;https://cdn.jsdelivr.net/npm//vega@5?noext&quot;,
      &quot;vega-lib&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-lib?noext&quot;,
      &quot;vega-lite&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext&quot;,
      &quot;vega-embed&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-embed@6?noext&quot;,
    };

    function loadScript(lib) {
      return new Promise(function(resolve, reject) {
        var s = document.createElement('script');
        s.src = paths[lib];
        s.async = true;
        s.onload = () =&gt; resolve(paths[lib]);
        s.onerror = () =&gt; reject(`Error loading script: ${paths[lib]}`);
        document.getElementsByTagName(&quot;head&quot;)[0].appendChild(s);
      });
    }

    function showError(err) {
      outputDiv.innerHTML = `&lt;div class=&quot;error&quot; style=&quot;color:red;&quot;&gt;${err}&lt;/div&gt;`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err =&gt; showError(`Javascript Error: ${err.message}&lt;br&gt;This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === &quot;function&quot; &amp;&amp; define.amd) {
      requirejs.config({paths});
      require([&quot;vega-embed&quot;], displayChart, err =&gt; showError(`Error loading script: ${err.message}`));
    } else if (typeof vegaEmbed === &quot;function&quot;) {
      displayChart(vegaEmbed);
    } else {
      loadScript(&quot;vega&quot;)
        .then(() =&gt; loadScript(&quot;vega-lite&quot;))
        .then(() =&gt; loadScript(&quot;vega-embed&quot;))
        .catch(showError)
        .then(() =&gt; displayChart(vegaEmbed));
    }
  })({&quot;config&quot;: {&quot;view&quot;: {&quot;continuousWidth&quot;: 400, &quot;continuousHeight&quot;: 300}}, &quot;layer&quot;: [{&quot;mark&quot;: &quot;line&quot;, &quot;encoding&quot;: {&quot;color&quot;: {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;symbol&quot;}, &quot;x&quot;: {&quot;type&quot;: &quot;temporal&quot;, &quot;field&quot;: &quot;date&quot;}, &quot;y&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;price&quot;, &quot;scale&quot;: {&quot;type&quot;: &quot;log&quot;}}}}, {&quot;mark&quot;: {&quot;type&quot;: &quot;rule&quot;, &quot;color&quot;: &quot;#aaa&quot;}, &quot;encoding&quot;: {&quot;x&quot;: {&quot;type&quot;: &quot;temporal&quot;, &quot;field&quot;: &quot;date&quot;}}, &quot;transform&quot;: [{&quot;filter&quot;: {&quot;selection&quot;: &quot;selector002&quot;}}]}, {&quot;mark&quot;: &quot;circle&quot;, &quot;encoding&quot;: {&quot;color&quot;: {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;symbol&quot;}, &quot;opacity&quot;: {&quot;condition&quot;: {&quot;value&quot;: 1, &quot;selection&quot;: &quot;selector002&quot;}, &quot;value&quot;: 0}, &quot;x&quot;: {&quot;type&quot;: &quot;temporal&quot;, &quot;field&quot;: &quot;date&quot;}, &quot;y&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;price&quot;, &quot;scale&quot;: {&quot;type&quot;: &quot;log&quot;}}}, &quot;selection&quot;: {&quot;selector002&quot;: {&quot;type&quot;: &quot;single&quot;, &quot;encodings&quot;: [&quot;x&quot;], &quot;on&quot;: &quot;mouseover&quot;, &quot;nearest&quot;: true, &quot;empty&quot;: &quot;none&quot;}}}, {&quot;mark&quot;: {&quot;type&quot;: &quot;text&quot;, &quot;align&quot;: &quot;left&quot;, &quot;dx&quot;: 5, &quot;dy&quot;: -5, &quot;stroke&quot;: &quot;white&quot;, &quot;strokeWidth&quot;: 2}, &quot;encoding&quot;: {&quot;color&quot;: {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;symbol&quot;}, &quot;text&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;price&quot;}, &quot;x&quot;: {&quot;type&quot;: &quot;temporal&quot;, &quot;field&quot;: &quot;date&quot;}, &quot;y&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;price&quot;, &quot;scale&quot;: {&quot;type&quot;: &quot;log&quot;}}}, &quot;transform&quot;: [{&quot;filter&quot;: {&quot;selection&quot;: &quot;selector002&quot;}}]}, {&quot;mark&quot;: {&quot;type&quot;: &quot;text&quot;, &quot;align&quot;: &quot;left&quot;, &quot;dx&quot;: 5, &quot;dy&quot;: -5}, &quot;encoding&quot;: {&quot;color&quot;: {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;symbol&quot;}, &quot;text&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;price&quot;}, &quot;x&quot;: {&quot;type&quot;: &quot;temporal&quot;, &quot;field&quot;: &quot;date&quot;}, &quot;y&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;price&quot;, &quot;scale&quot;: {&quot;type&quot;: &quot;log&quot;}}}, &quot;transform&quot;: [{&quot;filter&quot;: {&quot;selection&quot;: &quot;selector002&quot;}}]}], &quot;data&quot;: {&quot;url&quot;: &quot;https://vega.github.io/vega-datasets/data/stocks.csv&quot;}, &quot;height&quot;: 400, &quot;width&quot;: 700, &quot;$schema&quot;: &quot;https://vega.github.io/schema/vega-lite/v4.0.2.json&quot;}, {&quot;mode&quot;: &quot;vega-lite&quot;});
&lt;/script&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Data-Tables&quot;&gt;Data Tables&lt;a class=&quot;anchor-link&quot; href=&quot;#Data-Tables&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;You can display tables per the usual way in your blog:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;https://vega.github.io/vega-datasets/data/movies.json&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# display table with pandas&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Title&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;Worldwide_Gross&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;s1&quot;&gt;&amp;#39;Production_Budget&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;IMDB_Rating&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Title&lt;/th&gt;
      &lt;th&gt;Worldwide_Gross&lt;/th&gt;
      &lt;th&gt;Production_Budget&lt;/th&gt;
      &lt;th&gt;IMDB_Rating&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;The Land Girls&lt;/td&gt;
      &lt;td&gt;146083.0&lt;/td&gt;
      &lt;td&gt;8000000.0&lt;/td&gt;
      &lt;td&gt;6.1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;First Love, Last Rites&lt;/td&gt;
      &lt;td&gt;10876.0&lt;/td&gt;
      &lt;td&gt;300000.0&lt;/td&gt;
      &lt;td&gt;6.9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;I Married a Strange Person&lt;/td&gt;
      &lt;td&gt;203134.0&lt;/td&gt;
      &lt;td&gt;250000.0&lt;/td&gt;
      &lt;td&gt;6.8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Let's Talk About Sex&lt;/td&gt;
      &lt;td&gt;373615.0&lt;/td&gt;
      &lt;td&gt;300000.0&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;Slam&lt;/td&gt;
      &lt;td&gt;1087521.0&lt;/td&gt;
      &lt;td&gt;1000000.0&lt;/td&gt;
      &lt;td&gt;3.4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Images&quot;&gt;Images&lt;a class=&quot;anchor-link&quot; href=&quot;#Images&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;h3 id=&quot;Local-Images&quot;&gt;Local Images&lt;a class=&quot;anchor-link&quot; href=&quot;#Local-Images&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;You can reference local images and they will be copied and rendered on your blog automatically.  You can include these with the following markdown syntax:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;![](my_icons/fastai_logo.png)&lt;/code&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/my_icons/fastai_logo.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Remote-Images&quot;&gt;Remote Images&lt;a class=&quot;anchor-link&quot; href=&quot;#Remote-Images&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Remote images can be included with the following markdown syntax:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;![](https://image.flaticon.com/icons/svg/36/36686.svg)&lt;/code&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;img src=&quot;https://image.flaticon.com/icons/svg/36/36686.svg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Animated-Gifs&quot;&gt;Animated Gifs&lt;a class=&quot;anchor-link&quot; href=&quot;#Animated-Gifs&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Animated Gifs work, too!&lt;/p&gt;
&lt;p&gt;&lt;code&gt;![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif)&lt;/code&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Captions&quot;&gt;Captions&lt;a class=&quot;anchor-link&quot; href=&quot;#Captions&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;You can include captions with markdown images like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://www.fast.ai/images/fastai_paper/show_batch.png&quot; alt=&quot;&quot; title=&quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;Other-Elements&quot;&gt;Other Elements&lt;a class=&quot;anchor-link&quot; href=&quot;#Other-Elements&quot;&gt; &lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Tweetcards&quot;&gt;Tweetcards&lt;a class=&quot;anchor-link&quot; href=&quot;#Tweetcards&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Typing &lt;code&gt;&amp;gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20&lt;/code&gt; will render this:

&lt;center&gt;
&lt;div class=&quot;jekyll-twitter-plugin&quot;&gt;&lt;p&gt;There was a 'Bad Request' error fetching URL: '&lt;a href=&quot;https://twitter.com/jakevdp/status/1204765621767901185?s=20&quot;&gt;https://twitter.com/jakevdp/status/1204765621767901185?s=20&lt;/a&gt;'&lt;/p&gt;&lt;/div&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Youtube-Videos&quot;&gt;Youtube Videos&lt;a class=&quot;anchor-link&quot; href=&quot;#Youtube-Videos&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Typing &lt;code&gt;&amp;gt; youtube: https://youtu.be/XfoYk_Z5AkI&lt;/code&gt; will render this:

&lt;center&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/a&amp;gt;&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Boxes-/-Callouts&quot;&gt;Boxes / Callouts&lt;a class=&quot;anchor-link&quot; href=&quot;#Boxes-/-Callouts&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Typing &lt;code&gt;&amp;gt; Warning: There will be no second warning!&lt;/code&gt; will render this:
&lt;div class=&quot;flash flash-error&quot;&gt;
    &lt;svg class=&quot;octicon octicon-alert&quot; viewBox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; width=&quot;16&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 000 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 00.01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z&quot; /&gt;&lt;/svg&gt;
    &lt;strong&gt;Warning: &lt;/strong&gt;There will be no second warning!
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;Typing &lt;code&gt;&amp;gt; Important: Pay attention! It's important.&lt;/code&gt; will render this:
&lt;div class=&quot;flash flash-warn&quot;&gt;
    &lt;svg class=&quot;octicon octicon-zap&quot; viewBox=&quot;0 0 10 16&quot; version=&quot;1.1&quot; width=&quot;10&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M10 7H6l3-7-9 9h4l-3 7 9-9z&quot; /&gt;&lt;/svg&gt;
    &lt;strong&gt;Important: &lt;/strong&gt;Pay attention! It&amp;#8217;s important.
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;Typing &lt;code&gt;&amp;gt; Tip: This is my tip.&lt;/code&gt; will render this:
&lt;div class=&quot;flash flash-success&quot;&gt;
    &lt;svg class=&quot;octicon octicon-checklist&quot; viewBox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; width=&quot;16&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M16 8.5l-6 6-3-3L8.5 10l1.5 1.5L14.5 7 16 8.5zM5.7 12.2l.8.8H2c-.55 0-1-.45-1-1V3c0-.55.45-1 1-1h7c.55 0 1 .45 1 1v6.5l-.8-.8c-.39-.39-1.03-.39-1.42 0L5.7 10.8a.996.996 0 000 1.41v-.01zM4 4h5V3H4v1zm0 2h5V5H4v1zm0 2h3V7H4v1zM3 9H2v1h1V9zm0-2H2v1h1V7zm0-2H2v1h1V5zm0-2H2v1h1V3z&quot; /&gt;&lt;/svg&gt;
    &lt;strong&gt;Tip: &lt;/strong&gt;This is my tip.
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;Typing &lt;code&gt;&amp;gt; Note: Take note of this.&lt;/code&gt; will render this:
&lt;div class=&quot;flash&quot;&gt;
    &lt;svg class=&quot;octicon octicon-info&quot; viewBox=&quot;0 0 14 16&quot; version=&quot;1.1&quot; width=&quot;14&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z&quot; /&gt;&lt;/svg&gt;
    &lt;strong&gt;Note: &lt;/strong&gt;Take note of this.
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;Typing &lt;code&gt;&amp;gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine.&lt;/code&gt; will render in the docs:
&lt;div class=&quot;flash&quot;&gt;
    &lt;svg class=&quot;octicon octicon-info octicon octicon-info&quot; viewBox=&quot;0 0 14 16&quot; version=&quot;1.1&quot; width=&quot;14&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z&quot; /&gt;&lt;/svg&gt;
    &lt;strong&gt;Note: &lt;/strong&gt;A doc link to &lt;a href=&quot;https://www.fast.ai/&quot;&gt;an example website: fast.ai&lt;/a&gt; should also work fine.
&lt;/div&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://rroundtable.github.io/FastPages/images/chart-preview.png" /><media:content medium="image" url="https://rroundtable.github.io/FastPages/images/chart-preview.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">2019년 계획했던 일</title><link href="https://rroundtable.github.io/FastPages/2020/01/22/%EB%8A%A6%EC%9D%80-2019-%ED%9A%8C%EA%B3%A0.html" rel="alternate" type="text/html" title="2019년 계획했던 일" /><published>2020-01-22T00:00:00-06:00</published><updated>2020-01-22T00:00:00-06:00</updated><id>https://rroundtable.github.io/FastPages/2020/01/22/%EB%8A%A6%EC%9D%80-2019-%ED%9A%8C%EA%B3%A0</id><content type="html" xml:base="https://rroundtable.github.io/FastPages/2020/01/22/%EB%8A%A6%EC%9D%80-2019-%ED%9A%8C%EA%B3%A0.html">&lt;p&gt;2019년은 학생에서 사회인으로 나아가는 경계였다. 2019년에는 특히 좋은 사람들을 많이 만났고, 개인적으로 많은 도움을 받은 해라고 생각한다.&lt;/p&gt;

&lt;h4 id=&quot;1-딥러닝-논문-구현-목표-달성&quot;&gt;(1) 딥러닝 논문 구현: 목표 달성&lt;/h4&gt;

&lt;p&gt;지금도 어렵지만, 처음에 딥러닝 논문을 구현하려고 시도했을때는 정말 큰 벽처럼 느껴졌다.  이전에는 딥러닝 구현체를 주로 가져다 쓰는 식으로 공부를 지속하였고, 돌이켜보면 전혀 성장하지 못했던 시기이다.&lt;/p&gt;

&lt;p&gt;처음 딥러닝 논문을 구현하기로 마음먹은 것은 모두의 연구소 SafeAI랩에서 좋은 사람들을 만나서이다. 그 당시에는 구현하려는 주제가 명확했고, 누군가에게 피드백을 받을 환경이 조성되어 있어서 조금씩 성장했다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;처음에는 tensorflow code를 &lt;a href=&quot;https://github.com/RRoundTable&quot;&gt;keras code&lt;/a&gt;로 옮겨서 구현하는 연습을 하였다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;논문의 결과를 조금 더 명확하게 보여주기 위해서 &lt;a href=&quot;https://github.com/RRoundTable/EEN-with-Keras&quot;&gt;시각화&lt;/a&gt;에 힘을 쓰기도 하였다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;그리고, 논문의 처음부터 끝까지 오로지 &lt;a href=&quot;https://github.com/RRoundTable/hedged_instance_embedding&quot;&gt;나의 코드&lt;/a&gt;로 채우기도 하였다. 저자분이 한국분이셔서 커뮤니티에서 도움을 주기도 하였다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;2-코딩-테스트-합격하기&quot;&gt;(2) 코딩 테스트 합격하기&lt;/h4&gt;

&lt;p&gt;처음에는 딥러닝 엔지니어 직군이 코딩테스트를 보는지 몰랐다. 그래서 괜찮은 기회들을 놓치기도 했다. 코딩 테스트에 합격하기 위해서 &lt;a href=&quot;https://www.codility.com/&quot;&gt;Codility&lt;/a&gt; 를 활용하였지만, 나의 실력은 제자리 걸음이였다. 지금 생각해보면, 잘못된 방식으로 알고리즘을 대하고 있었다.&lt;/p&gt;

&lt;p&gt;결국은 2019년에 코딩 테스트에서는 모두 좋은 결과를 얻지 못했다.&lt;/p&gt;

&lt;h4 id=&quot;3-딥러닝-엔지니어로-인턴-경험-쌓기&quot;&gt;(3) 딥러닝 엔지니어로 인턴 경험 쌓기&lt;/h4&gt;

&lt;p&gt;수료 후에 인턴을 해야겠다는 계획을 가지고 있었다. 평소에 관심을 가지고 있던 의료기업들에 이메일 혹은 다른 매체로 지원서를 작성하였다. 한 기업에 면접을 보게 되었고,  긍정적인 인상을 가지고 회사에 입사하게 되었다.&lt;/p&gt;

&lt;p&gt;처음하는 사회생활이였다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;이런 점이 인상깊었다.&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;실제 인공지능 기술이 상업화되가는 과정을 지켜볼 수 있었다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;내가 이전에 놓치고 있던 개념들에 대해서 깨달음을 얻을 수 있었다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;능력있는 동료들&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;나에게 맡겨지는 책임과 권한&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;하지만,  나에게 버거웠던 것은&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;명확한 경쟁업체의 존재와 시장에 빠른 진입이 요구되었다.&lt;/li&gt;
  &lt;li&gt;경험해보지 않은 도메인에 대한 빠른 적응이 요구되었다.&lt;/li&gt;
  &lt;li&gt;문서체계 및 코드체계가 정해진 룰이 없었다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;처음하는 일이라서 잘하고 싶었던 마음이 더 컸다. 요구사항을 충족시키기 위해서 자신을 몰아세우고 있는 ‘나’를 발견하게 되었다.&lt;/p&gt;

&lt;p&gt;하지만, 다행스럽게도 주변에 조언을 구할 사람이 있었다. (감사합니다.)  혼자 생각하기보다 조언을 구하고 심정을 공유했던 것이 악순환을 벗어나는데 큰 도움이 되었다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;돌이켜보니,&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;일하면서 고민하고 고뇌했던 과정이 나에게 많은 영감을 주었다. 특히,  모델의 성능을 끌어올리기 위해서 정말 많은 고민과 스트레스를 받았는데, 그 과정에서 얻은 교훈은 나에게 많은 시도를 할 수 있게 해준 환경도 한 몫 했다고 생각한다. 또한 스트레스에 대해서 더 진지하게 생각해보는 계기가 되었다.&lt;/p&gt;

&lt;h2 id=&quot;2-2019년-계획하지-않았던-일&quot;&gt;2. 2019년 계획하지 않았던 일&lt;/h2&gt;

&lt;h4 id=&quot;1-풀잎스쿨-cpps&quot;&gt;(1) 풀잎스쿨 CPPS&lt;/h4&gt;

&lt;p&gt;기업에서 퇴사하기 약 1 ~ 2주전에 CPPS[competitive programming problem solving]을 시작하게 되었다.  &lt;a href=&quot;https://leetcode.com/&quot;&gt;leetcode&lt;/a&gt;에서 일주일에 다섯문제를 풀고 발표하는 형식으로 이루어졌다. 이 모임에 참여하기 전에는 다른 누군가에게 발표하는 과정의 필요성에 대해서 못느꼈다. 그리고 다른사람들의 중요성도 못 느꼈던 거 같다.&lt;/p&gt;

&lt;p&gt;하지만, 다른 사람들의 생각을 듣게 되면서, 새로운 방향성에 대해서 접하게 되었다. 또한, 내가 처음에 발표를 하는데 내용이 정리가 안되니까, 당황스러울 정도로 매끄럽지 못하게 발표하게 된적도 있다. 이런 경험을  한 후에는 앞에 나가기전에 잠깐 생각을 정리하기도 하고, discuss에서 다른 사람들이 어떤 생각으로 문제를 풀이하는지 어떤 것을 더 배울 수 있는지에 대한 고찰을 많이 하였다.&lt;/p&gt;

&lt;p&gt;혼자하는 것보다 여럿이 하니까, 더 깊은 생각과 생각을 정리할 수 있는 시간을 가질 수 있어서 좋았다.&lt;/p&gt;

&lt;h4 id=&quot;2-성남시-이노베이션-해커톤&quot;&gt;(2) 성남시 이노베이션 해커톤&lt;/h4&gt;

&lt;p&gt;퇴사 후에 해커톤에 참여하게 되었다. 좋은 분들과 함께 할 수 있어서 정말 재밌었다. 물론 그 당시에는 잠을 못자는게 힘들었다.&lt;/p&gt;

&lt;h4 id=&quot;3-의료인공지능-기업-면접&quot;&gt;(3) 의료인공지능 기업 면접&lt;/h4&gt;

&lt;p&gt;의료 도메인 인턴을 한 후, 헤드 헌터 업체를 통해서 Job description이 가끔 왔다. 그 중 하나의 기업에 면접을 보게 되었고, 나름 면접을 원할하게 볼 수 있었다. 하지만, 면접을 진행하면서 알게된 것은, 이전 기업과 너무나 유사한 사업분야였고, 가서 할 일도 비슷해보였다. 오퍼는 받았지만, 장기적으로는 기업과 나의 방향성이 일치하지 않을 것이 분명하여 죄송한 마음으로 거절하게 되었다.&lt;/p&gt;

&lt;h2 id=&quot;3-2019년을-보내고-난-후&quot;&gt;3. 2019년을 보내고 난 후&lt;/h2&gt;

&lt;p&gt;언제나처럼 시간이 너무나 빨랐다.  몇 가지 얻은 교훈이 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;성장을 하는데 중요한 자세는 어제보다 나은 오늘이다.&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;같은 실수를 반복하고 있지 않는지 돌이켜 볼 필요가 있다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;멀리가고 싶으면 함께 가는 것이 좋겠다.&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;아직도 여럿이 무엇을 하는데 익숙하지는 않으나, 노력중이다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;신체와 정신 모두 케어 받아야 한다.&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;내가 감당할 수 있는 스트레스 영역에 대한 이해가 필요하다. 불행하다고 느끼지 않는 선에서 노력하고 있다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-2020년을-맞이하며&quot;&gt;4. 2020년을 맞이하며&lt;/h2&gt;

&lt;p&gt;아직은 어떤 기술 스텍을 쌓아야 할지 명확하게 모르겠다.&lt;/p&gt;

&lt;p&gt;하지만, 점점 더 소프트웨어 개발자라는 직업이 매력적으로 느껴진다. 배움의 두려움을 이겨낼 수 있는 개발자가 되고 싶다.&lt;/p&gt;

&lt;p&gt;이런 기술 스텍들은 기본적으로 가져가고 싶다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;자료구조/알고리즘, 문제해결능력&lt;/li&gt;
  &lt;li&gt;운영체제&lt;/li&gt;
  &lt;li&gt;컴퓨터 네트워크&lt;/li&gt;
  &lt;li&gt;NLP, VISION의 중요한 개념들&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">2019년은 학생에서 사회인으로 나아가는 경계였다. 2019년에는 특히 좋은 사람들을 많이 만났고, 개인적으로 많은 도움을 받은 해라고 생각한다.</summary></entry><entry><title type="html">Word2vec: distributed representation</title><link href="https://rroundtable.github.io/FastPages/2020/01/14/word-representation.html" rel="alternate" type="text/html" title="Word2vec: distributed representation" /><published>2020-01-14T00:00:00-06:00</published><updated>2020-01-14T00:00:00-06:00</updated><id>https://rroundtable.github.io/FastPages/2020/01/14/word-representation</id><content type="html" xml:base="https://rroundtable.github.io/FastPages/2020/01/14/word-representation.html">&lt;blockquote&gt;
  &lt;p&gt;분산 표현(distributed representation) 방법은 기본적으로 분포 가설(distributional hypothesis)이라는 가정 하에 만들어진 표현 방법입니다. 이 가정은 &lt;strong&gt;‘비슷한 위치에서 등장하는 단어들은 비슷한 의미를 가진다’&lt;/strong&gt;라는 가정입니다.&lt;/p&gt;

  &lt;p&gt;reference: https://wikidocs.net/22660&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;1-cbowcontinuous-bag-of-words&quot;&gt;1. CBOW(Continuous Bag of Words)&lt;/h3&gt;

&lt;p&gt;주변에 있는 단어로 중간에 있는 단어를 예측하는 방법입니다. 중심단어를 예측하기 위해서 주변단어를 보는 범위를 window라고 합니다. 예를 들어서, 아래 이미지의 첫 번째 글에서 파란색 부분이 ‘fat’, ‘cat’이므로 window는 2입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wikidocs.net/images/page/22660/%EB%8B%A8%EC%96%B4.PNG&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;보통 딥 러닝이라함은, 입력층과 출력층 사이의 은닉층의 개수가 충분히 쌓인 신경망을 학습할 때를 말하는데 Word2Vec는 입력층과 출력층 사이에 하나의 은닉층만이 존재합니다. 이렇게 은닉층(hidden Layer)이 1개인 경우에는 일반적으로 심층신경망(Deep Neural Network)이 아니라 얕은신경망(Shallow Neural Network)이라고 부릅니다. 또한 Word2Vec의 은닉층은 일반적인 은닉층과는 달리 활성화 함수가 존재하지 않으며 룩업 테이블이라는 연산을 담당하는 층으로 일반적인 은닉층과 구분하기 위해 투사층(projection layer)이라고 부르기도 합니다.&lt;/p&gt;

  &lt;p&gt;reference: https://wikidocs.net/22660&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://wikidocs.net/images/page/22660/word2vec_renew_2.PNG&quot; /&gt;&lt;/p&gt;

&lt;p&gt;아래의 이미지를 보면 연산과정을 알 수 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$x_{cat}$: word one-hot vector&lt;/li&gt;
  &lt;li&gt;$W_{V * M}$:  input layer와 prejection layer사이의 matrix&lt;/li&gt;
  &lt;li&gt;$W’_{M* V}$: projection layer와 output layer간의 matrix&lt;/li&gt;
  &lt;li&gt;$V, M$: 단어의 개수, embedding 차원&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://wikidocs.net/images/page/22660/word2vec_renew_3.PNG&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wikidocs.net/images/page/22660/word2vec_renew_5.PNG&quot; /&gt;&lt;/p&gt;

&lt;p&gt;loss function으로는 cross-entropy 함수를 사용하게 됩니다.&lt;/p&gt;

&lt;p&gt;이제 역전파(Back Propagation)를 수행하면 W와 W’가 학습이 되는데, 학습이 다 되었다면 M차원의 크기를 갖는 W의 행이나 W’의 열로부터 어떤 것을 임베딩 벡터로 사용할지를 결정하면 됩니다. 때로는 W와 W’의 평균치를 가지고 임베딩 벡터를 선택하기도 합니다.&lt;/p&gt;

&lt;h3 id=&quot;2-skip-gram&quot;&gt;2. Skip-Gram&lt;/h3&gt;

&lt;p&gt;중간에 있는 단어로 주변의 단어들을 예측하는 방법입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wikidocs.net/images/page/22660/word2vec_renew_6.PNG&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;3-negative-sampling&quot;&gt;3. Negative Sampling&lt;/h3&gt;

&lt;p&gt;대부분 word2vec은 negative sampling을 함께 사용합니다. word2vec의 학습과정을 잘 살펴보면, 출력층에 있는 softmax 함수는 단어집합 크기의 vector내의 모든 값을 0과 1사이의 값이면서 모두 더하면 1이 되도록 바꾸는 작업을 수행합니다. 이는 그 단어가 주변단어와 전혀 상관이 없는 단어라도 똑같이 적용되는 부분입니다.&lt;/p&gt;

&lt;p&gt;만약 마지막 단계에서 ‘강아지’와 ‘고양이’와 같은 단어에 집중하고 있다면, Word2Vec은 사실 ‘돈가스’나 ‘컴퓨터’와 같은 연관 관계가 없는 수많은 단어의 임베딩을 조정할 필요가 없습니다. 전체 단어집합이 아니라 일부 단어집합에 대해서만 고려해도 되지 않을까요?&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;‘강아지’, ‘고양이’, ‘애교’와 같은 주변 단어들을 가져옵니다. 그리고 여기에 ‘돈가스’, ‘컴퓨터’, ‘회의실’과 같은 랜덤으로 선택된 주변 단어가 아닌 상관없는 단어들을 일부만 갖고옵니다. 이렇게 전체 단어 집합보다 훨씬 작은 단어 집합을 만들어놓고 마지막 단계를 이진 분류 문제로 바꿔버리는 겁니다. 즉, Word2Vec은 주변 단어들을 긍정(positive)으로 두고 랜덤으로 샘플링 된 단어들을 부정(negative)으로 둔 다음에 이진 분류 문제를 수행합니다.&lt;/p&gt;

  &lt;p&gt;reference: https://wikidocs.net/22660&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이는 기존의 다중 클래스 분류 문제를 이진 분류 문제로 바꾸면서도 연산량에 있어서 훨씬 효율적입니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;negative sampling은 word2vec을 만들때 현재 문장에 없는 단어를 전체 데이터셋에서 추출하는 방법이다. 목적 단어와 연관성이 없을 것이라고 추정되는 단어를 추출한다.&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;자주 뽑히는 단어일 수록 연관성이 낮다고 본다. 흔한 단어일수록 목적 단어와의 관계는 강하지 않기 때문&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;아래는 한 단어 $w_i$가  negative sample로 뽑힐 확률이다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$f(w_i)$ : $w_i$의 등장빈도&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(w_i) =\frac{f(w_i)^{0.75}}{\sum_{j=0}^n (f(w_j)^{0.75})}&lt;/script&gt;

&lt;h4 id=&quot;word2vec의-한계점&quot;&gt;word2vec의 한계점&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;out of vocalbulary에 대해서는 word representation을 얻을 수 없다.&lt;/li&gt;
  &lt;li&gt;infrequent words는 학습이 불안정하다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;glove&quot;&gt;Glove&lt;/h2&gt;

&lt;p&gt;카운트 기반과 예측기반을 모두 사용하는 방법론입니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;
      &lt;p&gt;LSA: 카운트 기반, 단어의미 유추 성능이 떨어짐.&lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
      &lt;p&gt;Word2Vec: 예측기반, 전체적인 통계정보를 반영하지 못함.&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;단어의 동시 등장 행렬은 행과 열을 전체 단어 집합의 단어들로 구성하고, window size내에서 k단어가 등장한 횟수를 기록하는 행렬을 말합니다. 이 행렬은 transpose를 해도 동일합니다. (대칭행렬)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;예시&lt;/p&gt;

  &lt;p&gt;I like deep learning&lt;/p&gt;

  &lt;p&gt;I like NLP&lt;/p&gt;

  &lt;p&gt;I enjoy flying&lt;/p&gt;
&lt;/blockquote&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;카운트&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;I&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;like&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;enjoy&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;deep&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;learning&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;NLP&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;flying&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;I&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;like&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;enjoy&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;deep&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;learning&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NLP&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;flying&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;co-occurrence-probability&quot;&gt;Co-occurrence probability&lt;/h3&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;동시 등장 확률 $P(k&lt;/td&gt;
      &lt;td&gt;i), P(k&lt;/td&gt;
      &lt;td&gt;i)$는 동시 등장 행렬로부터 특정 단어 i의 전체 등장 횟수를 카운트하고, 특정 단어 i가 등장했을 때 어떤 단어 k가 등장한 횟수를 카운트하여 계산한 조건부 확률입니다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;예를 들어서, 위의 동시등장행렬을 바탕으로 P(‘I’|’like’)를 구해보자. ‘I’ 는 총 3번 등장하였다. ‘I’와 ‘like’가 동시에 등장한 횟수는 2번이다. 따라서 P(‘I’|’like’) 는 2/3이다.
&lt;script type=&quot;math/tex&quot;&gt;P(A|B) = \frac{P(A) \cap P(B)}{P(B)}&lt;/script&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;table&gt;
    &lt;thead&gt;
      &lt;tr&gt;
        &lt;th style=&quot;text-align: left&quot;&gt;동시 등장 확률과 크기 관계 비(ratio)&lt;/th&gt;
        &lt;th style=&quot;text-align: left&quot;&gt;k=solid&lt;/th&gt;
        &lt;th style=&quot;text-align: left&quot;&gt;k=gas&lt;/th&gt;
        &lt;th style=&quot;text-align: left&quot;&gt;k=water&lt;/th&gt;
        &lt;th style=&quot;text-align: left&quot;&gt;k=fasion&lt;/th&gt;
      &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;td style=&quot;text-align: left&quot;&gt;P(k l ice)&lt;/td&gt;
        &lt;td style=&quot;text-align: left&quot;&gt;0.00019&lt;/td&gt;
        &lt;td style=&quot;text-align: left&quot;&gt;0.000066&lt;/td&gt;
        &lt;td style=&quot;text-align: left&quot;&gt;0.003&lt;/td&gt;
        &lt;td style=&quot;text-align: left&quot;&gt;0.000017&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td style=&quot;text-align: left&quot;&gt;P(k l steam)&lt;/td&gt;
        &lt;td style=&quot;text-align: left&quot;&gt;0.000022&lt;/td&gt;
        &lt;td style=&quot;text-align: left&quot;&gt;0.00078&lt;/td&gt;
        &lt;td style=&quot;text-align: left&quot;&gt;0.0022&lt;/td&gt;
        &lt;td style=&quot;text-align: left&quot;&gt;0.000018&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td style=&quot;text-align: left&quot;&gt;P(k l ice) / P(k l steam)&lt;/td&gt;
        &lt;td style=&quot;text-align: left&quot;&gt;8.9&lt;/td&gt;
        &lt;td style=&quot;text-align: left&quot;&gt;0.085&lt;/td&gt;
        &lt;td style=&quot;text-align: left&quot;&gt;1.36&lt;/td&gt;
        &lt;td style=&quot;text-align: left&quot;&gt;0.96&lt;/td&gt;
      &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;

  &lt;p&gt;위의 표를 통해 알 수 있는 사실은 solid가 등장했을 때 ice가 등장할 확률 0.00019은 solid가 등장했을 때 steam이 등장할 확률인 0.000022보다 약 8.9배 크다는 겁니다. 그도 그럴 것이 solid는 ‘단단한’이라는 의미를 가졌으니까 ‘증기’라는 의미를 가지는 steam보다는 당연히 ‘얼음’이라는 의미를 가지는 ice라는 단어와 더 자주 등장할 겁니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;loss-function&quot;&gt;Loss function&lt;/h3&gt;

&lt;p&gt;Embedding 된 중심단어와 주변 단어 벡터의 내적이 전체 코퍼스에서 동시 등장 확률이 되도록 모델을 학습시킨다.
&lt;script type=&quot;math/tex&quot;&gt;\mbox{doc product}(W_i, W_k) \approx P(k|i) = P_{ik}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;실제 학습에서는 아래의 식을 활용한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mbox{doc product}(W_i, W_k) \approx \log P(k|i) = \log P_{ik}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;$X$ : 동시 등장 행렬(Co-occurrence Matrix)&lt;/li&gt;
  &lt;li&gt;$X_{ij}$ : 중심 단어 i가 등장했을 때 윈도우 내 주변 단어 j가 등장하는 횟수&lt;/li&gt;
  &lt;li&gt;$X_i$:$\sum_{j}X_{ij}$: 동시 등장 행렬에서 i행의 값을 모두 더한 값&lt;/li&gt;
  &lt;li&gt;$P_{ik}$ :$P(k|i)$ = $\frac{X_{ik}}{X_i}$ : 중심 단어 i가 등장했을 때 윈도우 내 주변 단어 k가 등장할 확률
Ex) P(solid l ice) = 단어 ice가 등장했을 때 단어 solid가 등장할 확률&lt;/li&gt;
  &lt;li&gt;$\frac{P_{ik}}{P_{jk}}$ : $P_{ik}$를  $P_{jk}$로 나눠준 값
Ex) P(solid l ice) / P(solid l steam) = 8.9&lt;/li&gt;
  &lt;li&gt;$W_i$ : 중심 단어 i의 임베딩 벡터&lt;/li&gt;
  &lt;li&gt;$W_k$ : 주변 단어 k의 임베딩 벡터&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;embedding vector의 목적은 단어간의 관계를 잘 표현하는데 있습니다. 위에서 살펴본 $\frac{P_{ik}}{P_{jk}}$ 를 목적함수에 사용합니다. 먼저 함수의 input과 output을 정의해봅니다.
&lt;script type=&quot;math/tex&quot;&gt;F(W_i, W_j, W_k) =\frac{P_{ik}}{P_{jk}}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;input에서 output을 도출하는 방법은 많겠지만, 해당 연구에서는 두 단어간의 차이를 input으로 넣는 것을 제안합니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;F(W_i - W_j, W_k) =\frac{P_{ik}}{P_{jk}}&lt;/script&gt;

&lt;p&gt;그리고  선형 공간에서 두 vector간의 유사도를 보기 위해서 dot product를 선택했습니다. 
&lt;script type=&quot;math/tex&quot;&gt;F((W_i -W_j) ^ T W_k) =\frac{P_{ik}}{P_{jk}}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;정리하자면 선형공간에서 단어의 의미 관계를 표현하기 위해 뺄셈과 내적(dot procut)를 활용했습니다.&lt;/p&gt;

&lt;p&gt;여기서 함수 F는 중심단어와 주변단어의 선택기준이 무작위이기 때문에, 이 둘의 관계는 함수 F안에서 자유롭게 교환가능해야 합니다. 이 조건을 만족하기 위해서는 Homomorphism이라는 조건을 만족해야합니다.
&lt;script type=&quot;math/tex&quot;&gt;F(a+b) = F(a)F(b) \ \forall a, b \in R&lt;/script&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;In &lt;a href=&quot;https://en.wikipedia.org/wiki/Algebra&quot;&gt;algebra&lt;/a&gt;, a &lt;strong&gt;homomorphism&lt;/strong&gt; is a &lt;a href=&quot;https://en.wikipedia.org/wiki/Morphism&quot;&gt;structure-preserving&lt;/a&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Map_(mathematics)&quot;&gt;map&lt;/a&gt; between two &lt;a href=&quot;https://en.wikipedia.org/wiki/Algebraic_structure&quot;&gt;algebraic structures&lt;/a&gt; of the same type (such as two &lt;a href=&quot;https://en.wikipedia.org/wiki/Group_(mathematics)&quot;&gt;groups&lt;/a&gt;, two &lt;a href=&quot;https://en.wikipedia.org/wiki/Ring_(mathematics)&quot;&gt;rings&lt;/a&gt;, or two &lt;a href=&quot;https://en.wikipedia.org/wiki/Vector_space&quot;&gt;vector spaces&lt;/a&gt;).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Homomorphism의 조건하에서 a와 b가 각각 vector라면 scalar값이 나올 수 없지만 내적값이라고 하면 scalar값이 나올 수 있습니다.&lt;/p&gt;

&lt;p&gt;v1, v2, v3, v4 모두 vector입니다.
&lt;script type=&quot;math/tex&quot;&gt;F(v1^T v2 + v3^Tv4) = F(v1^T v2) F(v3^Tv4) \ \ \forall v1, v2, v3, v4 \in V&lt;/script&gt;
F는 두 vector의 차이를  받았기 때문에, 뺄셈에 대한 homomorphism으로 변경했습니다.&lt;/p&gt;

&lt;p&gt;(간단하게 덧셈 ~ 곱셈 관계를 뺄셈 ~ 나누기 관계로 치환하였습니다.)
&lt;script type=&quot;math/tex&quot;&gt;F(v1^T v2 - v3^Tv4) = \frac{F(v1^T v2)}{F(v3^Tv4)} \ \ \forall v1, v2, v3, v4 \in V&lt;/script&gt;
이제 glove식에 적용해보겠습니다.
&lt;script type=&quot;math/tex&quot;&gt;F((w_i - w_j)^Tw_k) = \frac{F(w_i^T w_k)}{F(w_j^T w_k)}= \frac{P_{ik}}{P_{jk}}&lt;/script&gt;
위의 식에서 조금 더 자세히 살펴보면,
&lt;script type=&quot;math/tex&quot;&gt;F(w_i^Tw_k) = P_{ik} = \frac{X_{ik}}{X_i}&lt;/script&gt;
또한 좌변을 풀어쓰면,
&lt;script type=&quot;math/tex&quot;&gt;F((w_i - w_j)^Tw_k) = F(w_i^T w_k - w_j^T w_k) = \frac{F(w_i^T w_k)}{F(w_j^T w_k)}&lt;/script&gt;
따라서 homomorphism을 형태와 일치하게 됩니다.&lt;/p&gt;

&lt;p&gt;그리고 이러한 조건을 만족시키는 함수는 지수 함수(Exponential function)입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/c/c6/Exp.svg/200px-Exp.svg.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$x^{a + b} = x ^ a * x ^ b$&lt;/li&gt;
  &lt;li&gt;$x^{a - b} = x ^ a / x ^ b$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이제 F를 $\exp$라고 해봅시다.
&lt;script type=&quot;math/tex&quot;&gt;\exp(w_i^T w_k - w_j^T w_k) = \frac{\exp(w_i^T w_k)}{\exp(w_j^T w_k)}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;학습의 안정성을 위해서, log를 사용합니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w_i^T w_k  = \log P_{ik}=\log (\frac{X_{ik}}{X_i})=\log X_{ik} - \log X_i&lt;/script&gt;

&lt;p&gt;위의 식은 homomorphism이 성립해야하지만, $\log X_i$ 때문에 성립하지 않게 됩니다. ($a - b \ne b-  a$)그래서 glove 연구팀은 $\log X_i$항을 bias $b_i$라는 상수항으로 대체합니다. 같은 이유로 $w_k$에 대한 bias $b_k$를 추가합니다.
&lt;script type=&quot;math/tex&quot;&gt;w_i^T w_k + b_i + b_k = \log X_{ik}&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mbox{loss function} = \sum_{m,n = 1}^V (w_m ^ T w_n + b_m + b_n - \log X_{mn})^2&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;$V$ : 단어집합의 크기&lt;/li&gt;
  &lt;li&gt;$X_{ik}$ 이 0이 될수도 있으므로 $\log(1+X_{ik})$로 바꾼다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;또한 동시등장행렬이 희소행렬일 가능성이 높다. glove 연구진은 동시 등장 행렬에서 등장 빈도의 값 $X_{ik}$가 매우 낮은 경우에는 정보가 거의 도움이 되지 않는다고 판단합니다. 따라서 동시등장행렬을 바탕으로 가중치함수를 구상하게 됩니다.&lt;/p&gt;

&lt;p&gt;가중치 함수의 그래프는 아래와 같습니다. 특정 값보다 크다면 모두 같은 가중치를 주게 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://wikidocs.net/images/page/22885/%EA%B0%80%EC%A4%91%EC%B9%98.PNG&quot; /&gt;
&lt;script type=&quot;math/tex&quot;&gt;f(x) = \min(1, (\frac{x}{x_{\max}})^{0.75})&lt;/script&gt;
최종적으로 목적함수는 아래의 식과 같습니다.
&lt;script type=&quot;math/tex&quot;&gt;\mbox{loss function} = \sum_{m,n = 1}^V f(X_{\min})(w_m ^ T w_n + b_m + b_n - \log X_{mn})^2&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&quot;fasttext&quot;&gt;FastText&lt;/h2&gt;

&lt;p&gt;FastText는 단어를 구성하는 Subwords(substrings)의 vector 합으로 단어 vector를 표현합니다. 이 방법은 typo(오식)가 있는 단어라 할지라도 비슷한 representation을 얻을 수 있으며, 새로운 단어에 대해서도 형태적 유사성을 고려한 적당한 word representation을 얻도록 도와줍니다.&lt;/p&gt;

&lt;p&gt;자연어 처리에서 자주 등장하는 문제는 (1) out of vocabulary, (2) infrequent words(모호성) 입니다. word2vec에서는 앞/뒤에 등장하는 단어로 가운데 단어를 예측하게 학습함으로서 문맥이 비슷한 단어를 유사한 vector로 표현합니다.&lt;/p&gt;</content><author><name></name></author><summary type="html">분산 표현(distributed representation) 방법은 기본적으로 분포 가설(distributional hypothesis)이라는 가정 하에 만들어진 표현 방법입니다. 이 가정은 ‘비슷한 위치에서 등장하는 단어들은 비슷한 의미를 가진다’라는 가정입니다. reference: https://wikidocs.net/22660</summary></entry><entry><title type="html">BERT 정리글</title><link href="https://rroundtable.github.io/FastPages/2019/12/30/BERT-%EC%A0%95%EB%A6%AC%EA%B8%80.html" rel="alternate" type="text/html" title="BERT 정리글" /><published>2019-12-30T00:00:00-06:00</published><updated>2019-12-30T00:00:00-06:00</updated><id>https://rroundtable.github.io/FastPages/2019/12/30/BERT-%EC%A0%95%EB%A6%AC%EA%B8%80</id><content type="html" xml:base="https://rroundtable.github.io/FastPages/2019/12/30/BERT-%EC%A0%95%EB%A6%AC%EA%B8%80.html">&lt;p&gt;&lt;strong&gt;BERT, Bidirectional Encoder Representations from Transformers&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;p&gt;BERT는  unlabeled text를 기반으로 deep bidirectional representation을 pretrain하기 위해서 만들어졌다. 이는 모든 layer에서 왼쪽과 오른쪽 모두의 context정보를 바탕으로 만들어진다.&lt;/p&gt;

&lt;p&gt;결과적으로 pretrained된 BERT 모델은 output layer을 추가하고 fine-tuning을 함으로써 question answering 그리고 language inference분야에서 state-of-the-art 성능을 낼 수 있다. 이는 task-specific한 구조의 변화없이 가능하다.&lt;/p&gt;

&lt;h2 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h2&gt;

&lt;p&gt;pretrained language representation을 활용하는데는 두 가지 전략이 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Feature-based: ELMO&lt;/p&gt;

    &lt;p&gt;task-specific한 architecture를 사용한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;fine-tuning: OpenAI GPT&lt;/p&gt;

    &lt;p&gt;task-specific한 parameter를 적게 사용한다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;위의 두 가지 전략은 pretraining을 하는동안 동일한 objective를 사용하게 된다. 또한 모두 unidirectional representation을 사용하고 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://mino-park7.github.io/images/2018/12/%EA%B7%B8%EB%A6%BC1-bert-openai-gpt-elmo-%EC%B6%9C%EC%B2%98-bert%EB%85%BC%EB%AC%B8.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;하지만, 본 논문에서는 unidirectional representation이 pretrained representation 능력을 제한한다고 주장하며,  이는 특히 fine-tuning 방법론에 영향을 많이 끼친다고 말한다. 가장 큰 한계는 standard language models가 unidirectional하며 이는 architecture를 선택할 때 많은 제한을 두게 된다. 예를 들어서, openAI GPT의 경우 left-to-right architecture를 사용한다. 모든 토큰은 self-attention layer에서 자기 자신보다 이전의 있는 토큰에만 영향을 끼친다. 이런 제한은 sentence-level task에서 sub-optimal하다.&lt;/p&gt;

&lt;p&gt;이 논문에서는 세 가지 contribution을 제공한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Bidirectional pre-training for language representation&lt;/li&gt;
  &lt;li&gt;pre-trained representation은  task-specific architecture의 필요성을 감소시킨다.&lt;/li&gt;
  &lt;li&gt;11가지 NLP task에 대해서 SOTA의 성능을 보인다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;2-related-work&quot;&gt;2. Related Work&lt;/h2&gt;

&lt;p&gt;pre-training general language representations에 관련된 연구들이다.&lt;/p&gt;

&lt;h3 id=&quot;21-unsupervised-feature-based-approaches&quot;&gt;2.1 Unsupervised Feature-based Approaches&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;word embedding vectors&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ELMO&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;22--unsupervised-fine-tuning-approaches&quot;&gt;2.2  Unsupervised Fine-tuning Approaches&lt;/h3&gt;

&lt;p&gt;word embedding parameter를 unlabeled text로 pre-trained 하는 것으로 연구가 시작되었다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;OpenAI GPT&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;fine-tuning approach는 학습과정에서 적은 parameter를 학습시키면 된다는 장점을 가지고 있다.&lt;/p&gt;

&lt;h3 id=&quot;23-transfer-learning-from-supervised-data&quot;&gt;2.3 Transfer Learning from Supervised Data&lt;/h3&gt;

&lt;p&gt;NLP, vision task에서 모두 tranfer learning은 효과적임을 보여주고 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Imagenet pretrained&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;3-bert-unified-architecture-across-different-tasks&quot;&gt;3. BERT: unified architecture across different tasks.&lt;/h2&gt;

&lt;p&gt;BERT는 두 가지 단계를 가지고 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;pre-training: unlabeled data를 이용해서 학습을 진행한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;fine-tuning: weight값을 pre-trained된 값으로 초기화해준다. 그 후 labeled data를 이용해서 지도학습을 진행하게 된다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Model Architecture&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;Transformer 기반으로 만들어졌다. Transformer 논문은 encoder decoder구조로 이루어져 있지만, BERT에서는 encoder 위주로 사용한다.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/1250095/49935094-73f99c80-ff13-11e8-8ba5-50a008ed4d20.png&quot; style=&quot;width: 50%&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;**Input/Output Representations **&lt;/p&gt;

    &lt;p&gt;down-stream task에서 잘 작동하려면, input representation이 single sentence 혹은 a pair of sentence에 모두 유연하게 반응할 수 있어야 한다.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/1250095/50039788-8e4e8a00-007b-11e9-9747-8e29fbbea0b3.png&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;해당 논문은 WordPiece embeddings을 사용하였다. 첫번째 token은 항상 [CLS]이다.(special classification token의 역할을 수행) 그리고 [CLS]에 반응하는 hidden state는 classification task를 위한 representation을 모으는 역할을 수행한다.&lt;/p&gt;

    &lt;p&gt;또한 두 가지 방법으로 sentence를 구분한다.&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;special token [SEP]를 이용하여 sentence를 구분한다.&lt;/li&gt;
      &lt;li&gt;각 sentence에 sentence embedding을 더하여 어떤 sentence정보를 가지고 있는지 알려준다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;31-pre-training-bert&quot;&gt;3.1 Pre-training BERT&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Task #1: Masked LM&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;직관적으로, bidirectional representation이 unidirectional representation보다 좋다는 것은 쉽게 알 수 있다. 하지만,  기존의 연구에서 사용하지 않은 이유는 바로 bidirectional representation을 하게 되면, 간접적으로 각 word가 자신에 대한 정보를 쉽게 얻을 수 있게 되며, 모델이 multi layerd contex에서 target word를 참조하기 힘들게 한다.&lt;/p&gt;

    &lt;p&gt;위의 한계점을 극복하고 deep bidirectional representation한 train을 하기 위해서 해당 연구에서는 input token중 일부를 랜덤하게 마스크하고 이렇게 mask된 단어들을 학습하도록 유도하였다. 이를 masked LM(MLM)이라고 한다. 실험적으로 약 15%의 token을 마스크하는것이 효과적이였다.&lt;/p&gt;

    &lt;p&gt;하지만, fine-tuning을 할 때, 문제가 발생한다. 바로 [Mask] 했던 token들은 fine-tuning과정에서는 발생하지 않기 때문이다. 이러한 문제점을 해결하기 위해서, 다음과 같은 조치를 취하였다.&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;i-token이 mask되었다면, 80% 확률로 [Mask]로 대체한다.&lt;/p&gt;

        &lt;p&gt;나는 학생이다. -&amp;gt; 나는 [Mask]이다.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;i-token이 mask되었다면, 10% 확률로 random하게 다른 단어로 대체한다.&lt;/p&gt;

        &lt;p&gt;나는 학생이다 -&amp;gt; 나는 아파트이다.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;i-token이 mask되었다면,  10% 확률로 변화시키지 않는다.&lt;/p&gt;

        &lt;p&gt;나는 학생이다. -&amp;gt; 나는 학생이다.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;

    &lt;p&gt;이런 조치를 취하게 되면, Transformer layer가  cross entropy loss로 학습을 진행하게 된다. 참고로 random하게 단어를 변화시키는 확률은 $0.15 * 0.1 = 0.015$ 로 모델의 표현력을 저하시키지 않는다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Task #2: Next Sentence Prediction(NSP)&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;Question Answering, Natural Language Inference와 같은 task에서 두 문장 사이의 관계를 파악하는 것은 중요하다. 이는 language modeling에서 직접적으로 관계를 파악하기 힘들다. 두 문장 사이의 관계를 파악하기 위해서 해당 논문은 next sentence prediction task로 pre-train을 하였다.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;특히 A문장과 B문장을 고를때, 50%확률로 B가 실제로 뒤에 있는 문장이다.&lt;/li&gt;
      &lt;li&gt;나머지 50% 확률로 random하게 배치한다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;하지만, 이전 연구에서는 sentence embedding만 down-task에 전이가 한다. (BERT는 모든 parameter를 전이한다.)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;32-fine-tunning-bert&quot;&gt;3.2 Fine-tunning BERT&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;self-attention layer의 영향으로 fine-tuning은 매우 순조롭다.&lt;/li&gt;
  &lt;li&gt;input sequence에 대해서 일정한 차원수의 representation 결과를 얻고 싶기 때문에, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[CLS]&lt;/code&gt; token의 &lt;strong&gt;Transformer output&lt;/strong&gt;값을 사용합니다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[CLS]&lt;/code&gt; token의 벡터는 H차원을 가집니다. $C∈R^H$&lt;/li&gt;
  &lt;li&gt;여기서 &lt;strong&gt;classify하고 싶은 갯수(K)에 따라 classification layer&lt;/strong&gt;를 붙여 줍니다. classification layer : $W∈R^{K×H} W∈R^{K×H}$&lt;/li&gt;
  &lt;li&gt;label probabilities는 &lt;strong&gt;standard softmax&lt;/strong&gt;로 계산 됩니다.$P=softmax(CWT)P=softmax(CWT)$&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;W matrix와 BERT의 모든 파라미터가 같이 fine-tuning 됩니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;hyperparmeter&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;Batch size&lt;/strong&gt;: 16, 32 &lt;strong&gt;Learning rage (Adam)&lt;/strong&gt;: 5e-5, 3e-5, 2e-5 Number of epochs : 3, 4&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;pretraining과 비교했을때, 상대적으로 fine-tuning은 적은 비용으로 학습시킬수 있다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;fine-tuning시 dataset의 크기가 클수록 hyperparameter의 영향을 덜 받고 잘 training됨을 관측할 수 있었다고 합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;33-comparision-of-bert-elmo-and-openai-gpt&quot;&gt;3.3 Comparision of BERT, ELMO and OpenAI GPT&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://mino-park7.github.io/images/2018/12/%EA%B7%B8%EB%A6%BC1-bert-openai-gpt-elmo-%EC%B6%9C%EC%B2%98-bert%EB%85%BC%EB%AC%B8.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;BERT와 OpenAI GPT는 fine-tuning approach인 반면에, ELMo는 feature-based approach이다.&lt;/li&gt;
  &lt;li&gt;BERT와 OpenAI GPT는 유사한 pre-training방법론을 사용하였다.&lt;/li&gt;
  &lt;li&gt;BERT와 ELMo는 bidirectional representation을 얻는다. OpenAI GPT는 unidirectional representation을 사용한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4experiments&quot;&gt;4.Experiments&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Fine-tunning on Different Tasks&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://mino-park7.github.io/images/2019/02/%EA%B7%B8%EB%A6%BC4-bert-experiment-result.png&quot; style=&quot;width: 80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 그림은 각 task에 대한 fine-tuning 방법론을 시각화한 것이다. (a), (b)는 sentence level, (c)와 (d)는 token-level task이다. 참고로 [CLS]는 classification을 위한 단어이고, [SEP]는 연속적이지 않은 token을 나누기 위한 단어이다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;GLUE&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;SQuAD v1.1&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;SQuAD v2.0&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;SWAG&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;5-ablation-studies&quot;&gt;5. Ablation Studies&lt;/h2&gt;

&lt;h3 id=&quot;51-effect-of-pre-training-tasks&quot;&gt;5.1 Effect of Pre-training Tasks&lt;/h3&gt;

&lt;h3 id=&quot;51-effect-of-model-size&quot;&gt;5.1 Effect of Model Size&lt;/h3&gt;

&lt;h3 id=&quot;53-feature-based-approach-with-bert&quot;&gt;5.3 Feature-based Approach with BERT&lt;/h3&gt;

&lt;h2 id=&quot;6-conclusion&quot;&gt;6. Conclusion&lt;/h2&gt;</content><author><name></name></author><summary type="html">BERT, Bidirectional Encoder Representations from Transformers</summary></entry><entry><title type="html">Content</title><link href="https://rroundtable.github.io/FastPages/2019/12/28/Sorting-Algorithm.html" rel="alternate" type="text/html" title="Content" /><published>2019-12-28T00:00:00-06:00</published><updated>2019-12-28T00:00:00-06:00</updated><id>https://rroundtable.github.io/FastPages/2019/12/28/Sorting-Algorithm</id><content type="html" xml:base="https://rroundtable.github.io/FastPages/2019/12/28/Sorting-Algorithm.html">&lt;ul&gt;
  &lt;li&gt;Insert sort&lt;/li&gt;
  &lt;li&gt;Merge sort&lt;/li&gt;
  &lt;li&gt;Quick sort&lt;/li&gt;
  &lt;li&gt;Heap sort&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;insert-sort&quot;&gt;Insert Sort&lt;/h2&gt;

&lt;p&gt;insert sort는 일반적으로 적은 수의 요소들을 정렬할 때 유리하다.&lt;/p&gt;

&lt;p&gt;insert sort는 배열이 주어졌을 때, 순차적으로 순회하면서 각 요소의 올바른 위치로 정렬한다.  만약, i 번째까지 순회하였다면, 0 ~ i번째의 배열은 0 ~ i번째 배열의 성분 기준으로 모두 알맞은 위치에 정렬된 상태이다.  i + 1번째 요소는 알맞게 정렬된 0 ~ i번째 배열기준으로 알맞은 위치로 삽입된다.&lt;/p&gt;

&lt;p&gt;이를 의사코드로 나타내면 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 알맞은 위치로 가야하는 성분
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# Insert into the sorted sequence A[:i]
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;
        
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이해를 돕기 위해서 아래의 이미지를 첨부하였다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F2774593451C1629402&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;loop-invariants-and-the-correctness-of-insertion-sort&quot;&gt;Loop invariants and the correctness of insertion sort&lt;/h3&gt;

&lt;p&gt;위의 의사코드에서 i index는 현재 정렬해야 되는 성분을 의미하며, A[:i]는 0 ~ i - 1의 성분들을 의미한다. 이 때 A[:i ]는 정렬되기전의 A[:i]와 구성요소는 모두 같으면서 정렬된 배열을 의미한다. 이러한 성질을 CS에서는 loop invariants라고 한다. 그리고 이런 성질은 correcteness를 증명하는데 사용된다.&lt;/p&gt;

&lt;p&gt;loop invariants는 3가지 조건을 충족해야한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Initialization: 첫 번째 순회에서 참이어야 한다.&lt;/li&gt;
  &lt;li&gt;Maintenance: 순회를 돌기전에 참이라면, 다음순회를 시작하기 전까지 참이어야 한다.&lt;/li&gt;
  &lt;li&gt;Termination: 전체 순회가 끝날때, loop invariant가 해당 알고리즘이 정확하다는 것을 알려줘야 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;예시를 들어보겠다.&lt;/p&gt;

&lt;p&gt;A = [0, 3, 8, 2, 1, 4]&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Initialization&lt;/p&gt;

    &lt;p&gt;index번호가 1부터 시작한다.(A[i] = 3) 따라서 A[:i] = [0]이다. 그리고 이는 항상 참이다.\&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Maintenance&lt;/p&gt;

    &lt;p&gt;순회를 하는 동안 i는 1, 2, 3, 4 …의 값을 가질 것이다. 정렬된 subarray A[:i]는 기존의 정렬되지 않은 A[:i]와 구성요소는 같다. (Loop invariant)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Termination&lt;/p&gt;

    &lt;p&gt;전체 순회가 종료되었을 때를 생각해보자. (i = len(A) - 1)&lt;/p&gt;

    &lt;p&gt;순회를 할때마다, i는 1씩 증가하게 되므로, 알고리즘이 종료될 때는 i=len(A) - 1이 된다. 이때 subarray는 A[:i] 이므로 0 ~ len(A) - 2의 범위를 가지게 된다. (정렬된 상태이다.) 그러므로 마지막 성분 A[i]만 올바른 위치에 정렬하면 된다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;analyzing-algorithms&quot;&gt;Analyzing algorithms&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;input size: array size&lt;/li&gt;
  &lt;li&gt;running time: 주어진 input에 대해서 주된 연산의 call 수&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://i.stack.imgur.com/AxoMa.png&quot; /&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;T(n) = c_1n + c_2(n-1) + c_4(n-1) + c_5 \sum_{j=2}^n t_j + c_6 \sum_{j=2}^n (t_j - 1) + c_7 \sum_{j=2}^n (t_j - 1) + c_8 (n-1)&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;best case: O(N)/O(1)
    &lt;ul&gt;
      &lt;li&gt;모두 정렬되어 있을 경우 $c_5 \sum_{j=2}^n t_j + c_6 \sum_{j=2}^n (t_j - 1) + c_7 \sum_{j=2}^n (t_j - 1)$ 은 무시해도 좋다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;worst case: O(N^2)/O(1)
    &lt;ul&gt;
      &lt;li&gt;모두 거꾸로 정렬되어 있을 경우&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;order of growth: O(N^2)/O(1)
    &lt;ul&gt;
      &lt;li&gt;해당 알고리즘의 upper bound&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;merge-sort-devide-and-conquer&quot;&gt;Merge sort: devide-and-conquer&lt;/h2&gt;

&lt;p&gt;devide-and-conquer 방법론은 문제를 본래의 문제와 유사한 작은 문제로 나누어 해결한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn.kastatic.org/ka-perseus-images/98c02634ee7f970a6bfb0812cc1495bacb462282.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;devide:  problem -&amp;gt; subproblem, subproblem의 성질은 기존의 problem과 동일하다.&lt;/li&gt;
  &lt;li&gt;conquer:  subproblem의 크기가 충분히 작다면, 해를 도출한다.&lt;/li&gt;
  &lt;li&gt;combine: subproblem을 해를 고려하여 상위의 problem의 문제를 해결한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;merge sort는 전형적인 devide-and-conquer 방법론이다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;devide:  array를 2개의 작은 array로 나눈다.&lt;/li&gt;
  &lt;li&gt;conquer: 두개의 작은 array를 재귀적으로 정렬한다.&lt;/li&gt;
  &lt;li&gt;combine: 두개의 정렬된 작은 array를 합치면서, 정렬된 array를 도출한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/e/e6/Merge_sort_algorithm_diagram.svg/220px-Merge_sort_algorithm_diagram.svg.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;merge sort는 두 가지 방법으로 구현할 수 있다.  아래는 python으로 제작한 의사코드이다.&lt;/p&gt;

&lt;h3 id=&quot;top-down-approach-recursive&quot;&gt;Top-Down approach: recursive&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;merge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    A[p:q+1]와 A[q+1:r+1]을 합친다. 
    A: 합쳐지기 전 array, A[p:q+1], A[q+1:r+1]은 각각 정렬된 상태
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
       	&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;merge_sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'''
    A: 정렬되지 않은 array
    p: left index
    r: right index
    '''&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;merge_sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;merge_sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;merge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;bottom-up-approach-iterative&quot;&gt;Bottom-up approach: iterative&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;merge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    A[p:q+1]와 A[q+1:r+1]을 합친다. 
    A: 정렬되지 않은 array
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
       	&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;group_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;group_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
   	&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;merge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;group_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;group_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;group_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
        
    
    
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;loop-invariant&quot;&gt;Loop invariant&lt;/h3&gt;

&lt;p&gt;insert sort와 마찬가지로 loop invariant 성질을 이용하여 corrteness를 증명할 수 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Initialization: 초기에는 subarray가 비워진 상태로 시작한다.&lt;/li&gt;
  &lt;li&gt;Maintainance: 위의 의사코드에서 알 수 있듯이 subarray의 성분의 index는 바뀌지만 전체 성분은 변하지 않는다.&lt;/li&gt;
  &lt;li&gt;Termination: 마지막 두 개의 subarray를 합칠 때를 고려해보자. 각각의 subarray는 정렬되어 있는 상태이다. 따라서 merge 알고리즘을 그대로 적용한다면, 결과는 모두 정렬되어 나올 것이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;analyzing-divide-and-conquer-algorithms&quot;&gt;Analyzing divide-and-conquer algorithms&lt;/h3&gt;

&lt;p&gt;recursive한 알고리즘을 사용했다면, running time을 recurrence equation을 활용해서 표현할 수 있다. 아래는 예시이다.
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
T(n) = \begin{cases} O(1)  &amp; \mbox{if } n \le c, \\
aT(n/b) + D(n) + C(n) &amp; \mbox{otherwise}\end{cases} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;subarray가 충분히 작다면: $\mbox{if } n &amp;gt; c$&lt;/li&gt;
  &lt;li&gt;$T(n/b)$:  $n/b$  subarray의 크기, $a$ 는 subarray의 개수&lt;/li&gt;
  &lt;li&gt;$D(n)$: array를 subarray로 나누는데 걸리는 시간&lt;/li&gt;
  &lt;li&gt;$C(n)$: combine&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이제 merge sort를 분석해보자.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;divide: $D(n) = O(1)$, subarray의 중간까지만 나눈다.&lt;/li&gt;
  &lt;li&gt;conquer: $2T(N/2)$&lt;/li&gt;
  &lt;li&gt;combine: $C(n) = O(n)$&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
T(n) = \begin{cases} O(1)  &amp; \mbox{if } n \le c, \\
2T(n/2) + O(n) &amp; \mbox{otherwise}\end{cases} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;img src=&quot;https://www.researchgate.net/profile/Wolfgang_Schreiner2/publication/267856474/figure/fig9/AS:669218265636872@1536565476357/Recursion-Tree-for-MERGESORT.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;time complexity: O(nlogn)&lt;/li&gt;
  &lt;li&gt;space complexity: O(nlogn)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;quick-sort&quot;&gt;Quick Sort&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;worst case: O(n ^ 2)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;expected: O(nlogn) constant factor가 다른 기법에 비해서 작은 편이다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;quick sort 역시 divide-and-conquer의 한 방법이다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Divide: Array를 두개의 subarray로 나눈다. $A[p…r]$을 $A[p..q-1]$,$A[q + 1.. r]$&lt;/p&gt;

    &lt;p&gt;로 나누는 것이다. $A[p..q-1]$은 $A[q]$보다 작거나 같다. 또한 $A[q + 1.. r]$은 $A[q]$ 보다 크거나 같다. 나중에 언급하지만 $A[q]$는 pivot이다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Conquer: $A[p..q-1]$,$A[q + 1.. r]$를 재귀적으로 정렬한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Combine: subarray가 모두 정렬되어 있기 때문에, 따로 결합할 필요가 없다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;quick sort의 의사코드는 아래와 같다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;quick_sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;quick_sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;quick_sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# pivot value
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# pivot보다 왼쪽에 위치해야한다.
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
   	&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;partition이 이해가 안되다면 아래의 그림을 참고해보면 좋다. 참고로 i index는 pivot보다 작거나 같은 값을 가졌다는 것을 알려주며, j index는 탐색하는 의도로 구성되었다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.codingeek.com/wp-content/uploads/2016/06/word-image-2.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;loop-invariant-1&quot;&gt;Loop invariant&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Initialization&lt;/p&gt;

    &lt;p&gt;i = p - 1 이고 j = p 이다. p와 i 사이에는 value가 없다. 그리고  i + 1과 j- 1사이에도  아무것도 없다. 따라서 loop invariant 조건을 충족한다. (swap이 일어나지 않는다.)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Maintainance&lt;/p&gt;

    &lt;p&gt;위의 그림에서 볼 수 있듯이,  pivot value에 따라서 성분의 배치가 달라질 수 있다. 하지만, 배치만 달라질뿐 전체 성분은 변하지 않는다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Termination&lt;/p&gt;

    &lt;p&gt;알고리즘이 종료될 때는 3가지 set이 주어진다. pivot보다 작은 set, pivot, pivot보다 큰 set 이렇게 주어지게 되는데, 이는 내부적으로 모두 정렬된 상태이다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;performance-of-quicksort&quot;&gt;Performance of quicksort&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;worst-case&lt;/p&gt;

    &lt;p&gt;partitioning이 1: n-1식으로 계속해서 나눠지면 최악의 성능 O(N^2)이다.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;http://staff.ustc.edu.cn/~csli/graduate/algorithms/book6/157_a.gif&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;balanced partioning&lt;/p&gt;

    &lt;p&gt;partitioning이 모두 고루게 나눠지면 성능은 O(NlogN)이다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;http://staff.ustc.edu.cn/~csli/graduate/algorithms/book6/158_b.gif&quot; /&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Insert sort Merge sort Quick sort Heap sort</summary></entry><entry><title type="html">Big-O notation 정리하기</title><link href="https://rroundtable.github.io/FastPages/2019/12/28/Big-O-notation-%EC%A0%95%EB%A6%AC%ED%95%98%EA%B8%B0.html" rel="alternate" type="text/html" title="Big-O notation 정리하기" /><published>2019-12-28T00:00:00-06:00</published><updated>2019-12-28T00:00:00-06:00</updated><id>https://rroundtable.github.io/FastPages/2019/12/28/Big-O-notation-%EC%A0%95%EB%A6%AC%ED%95%98%EA%B8%B0</id><content type="html" xml:base="https://rroundtable.github.io/FastPages/2019/12/28/Big-O-notation-%EC%A0%95%EB%A6%AC%ED%95%98%EA%B8%B0.html">&lt;blockquote&gt;
  &lt;p&gt;In &lt;a href=&quot;https://en.wikipedia.org/wiki/Computer_science&quot;&gt;computer science&lt;/a&gt;, big O notation is used to &lt;a href=&quot;https://en.wikipedia.org/wiki/Computational_complexity_theory&quot;&gt;classify algorithms&lt;/a&gt; according to how their running time or space requirements grow as the input size grows.[&lt;a href=&quot;https://en.wikipedia.org/wiki/Big_O_notation#cite_note-quantumcomplexity-3&quot;&gt;3]&lt;/a&gt; In &lt;a href=&quot;https://en.wikipedia.org/wiki/Analytic_number_theory&quot;&gt;analytic number theory&lt;/a&gt;, big O notation is often used to express a bound on the difference between an &lt;a href=&quot;https://en.wikipedia.org/wiki/Arithmetic_function&quot;&gt;arithmetical function&lt;/a&gt; and a better understood approximation; a famous example of such a difference is the remainder term in the &lt;a href=&quot;https://en.wikipedia.org/wiki/Prime_number_theorem&quot;&gt;prime number theorem&lt;/a&gt;.&lt;/p&gt;

  &lt;p&gt;reference: https://en.wikipedia.org/wiki/Big_O_notation&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;formal-definition&quot;&gt;Formal definition&lt;/h2&gt;

&lt;p&gt;$F$ 는 real or complex valued function이며 , $g$는 real valued function이다. 두 함수는 무한한 양의 실수의 subset으로 정의된다. 따라서 $g(x)$는 x가 충분히 큰 값일때 항상 양수이다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;F(x) = O(g(x)) \ \text{as} \ x \rightarrow \infty&lt;/script&gt;

&lt;p&gt;충분히 큰 x값을 가질 수 있을때만, $F(x)$의 절대값의 최대값이 $g(x)$에 양의 상수를 곱한 것을 넘지 못할 때, $F(x) = O(g(x))$라고 표현한다. (Upper Bound)이를 아래 식으로 표현한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\rvert F(x) \rvert \le Mg(x) \text{for all } x \ge x_0&lt;/script&gt;

&lt;p&gt;이를 간단하게 아래의 이미지로 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/8/89/Big-O-notation.png/300px-Big-O-notation.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;파란색 선은 $Mg(x)$ 를 빨간색 선은 $F(x)$를 의미한다. $x_0$보다 큰 x값을 가지면, $F(x)$는 항상 $Mg(x)$보다 작으며, 이는 $F(x)$의 upper bound가 $Mg(x)$라는 것을 의미한다.&lt;/p&gt;</content><author><name></name></author><summary type="html">In computer science, big O notation is used to classify algorithms according to how their running time or space requirements grow as the input size grows.[3] In analytic number theory, big O notation is often used to express a bound on the difference between an arithmetical function and a better understood approximation; a famous example of such a difference is the remainder term in the prime number theorem. reference: https://en.wikipedia.org/wiki/Big_O_notation</summary></entry><entry><title type="html">Transformer 구조</title><link href="https://rroundtable.github.io/FastPages/2019/11/18/attention-is-all-you-need-%EC%A0%95%EB%A6%AC%EA%B8%80.html" rel="alternate" type="text/html" title="Transformer 구조" /><published>2019-11-18T00:00:00-06:00</published><updated>2019-11-18T00:00:00-06:00</updated><id>https://rroundtable.github.io/FastPages/2019/11/18/attention-is-all-you-need-%EC%A0%95%EB%A6%AC%EA%B8%80</id><content type="html" xml:base="https://rroundtable.github.io/FastPages/2019/11/18/attention-is-all-you-need-%EC%A0%95%EB%A6%AC%EA%B8%80.html">&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/27891090/69061756-2196f900-0a5d-11ea-9249-2401a60830d6.png&quot; style=&quot;width:50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 이미지는 Transformer의 구조이다. encoder와 decoder 구조로 이루어져 있다. 마지막 encoder layer의 output이 각 decoder stack에 input으로 들어가게 된다. (&lt;strong&gt;residual connection&lt;/strong&gt;) 각 encoder layer와 decoder layer는 모두 동일한 구조를 가지나 서로 parameter를 공유하지 않는다.  아래의 그림처럼 논문에서는 각 6개의 layer를 가지고 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/27891090/69062040-aaae3000-0a5d-11ea-9d43-e5162aa70eb6.png&quot; style=&quot;width:50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;아래의 이미지는 encoder와  decoder의 세부 구조이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://jalammar.github.io/images/t/Transformer_decoder.png&quot; style=&quot;width: 80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;각 세부 layer사이에는  Normalization 및  bias를 더하는 과정이 추가된다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;h2 id=&quot;matrix-calculation-of-self-attention&quot;&gt;Matrix Calculation of Self-Attention&lt;/h2&gt;

  &lt;p&gt;이제  복수의 embeddinb vector를 matrix 연산으로 대체하는 과정을 살펴보자. 위의 그림과는 다르게 embedding vector가 matrix형태로 제공되어서 병렬 연산이 가능해졌다. 아래의 이미지 참고.&lt;/p&gt;

  &lt;p&gt;&lt;img src=&quot;http://jalammar.github.io/images/t/self-attention-matrix-calculation.png&quot; style=&quot;width: 50%&quot; /&gt;&lt;/p&gt;

  &lt;p&gt;&lt;img src=&quot;http://jalammar.github.io/images/t/self-attention-matrix-calculation-2.png&quot; style=&quot;width: 50%&quot; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;attention&quot;&gt;Attention&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/27891090/69063207-72a7ec80-0a5f-11ea-8e62-d4acc8bb5044.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;1-scaled-dot-product-attention&quot;&gt;1. Scaled Dot-Product Attention&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Attention(Q, K, V) = softmax(\frac{QK^T}{\sqrt{d_k}}) V&lt;/script&gt;

&lt;blockquote&gt;
  &lt;p&gt;Query, Key -  Value의 역할&lt;/p&gt;

  &lt;ul&gt;
    &lt;li&gt;Query: , matrix&lt;/li&gt;
    &lt;li&gt;Key: 각 embedding vector의 key, matrix&lt;/li&gt;
    &lt;li&gt;Value: 각 key가 가지고 있는 value, matrix&lt;/li&gt;
  &lt;/ul&gt;

  &lt;p&gt;&lt;strong&gt;추가적인 설명&lt;/strong&gt; 우선 query와 key, value에 대해서 설명하면 query가 어떤 단어와 관련되어 있는지 찾기 위해서 모든 key들과 연산한다. 여기서 실제 연산을 보면 query와 key를 dot-product한뒤 softmax를 취하는데, 의미하는 것은 하나의 query가 모든 key들과 연관성을 계산한뒤 그 값들을 확률 값으로 만들어 주는 것이다. 따라서 query가 어떤 key와 높은 확률로 연관성을 가지는지 알게 되는 것이다. 이제 구한 확률값을 value에 곱해서 value에 대해 scaling한다고 생각하면된다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;추가적인 설명&lt;/strong&gt; key와 value는 사실상 같은 단어를 의미한다. 하지만 두개로 나눈 이유는 key값을 위한 vector와 value를 위한 vector를 따로 만들어서 사용한다. key를 통해서는 각 단어와 연관성의 확률을 계산하고 value는 그 확률을 사용해서 attention 값을 계산하는 용도이다.&lt;/p&gt;

  &lt;p&gt;reference:  https://reniew.github.io/43/&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;아래의 이미지는 scaled dot product attention과정의 일부이다. query, key 그리고 value는 각 $W^Q, W^K, W^V$matrix와 dot product를 진행한 결과이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://jalammar.github.io/images/t/transformer_self_attention_vectors.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그리고  query와 key의 dot product의 결과를 $\sqrt{d_k}$만큼 scaling 해준다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://jalammar.github.io/images/t/self-attention-output.png&quot; /&gt;\&lt;/p&gt;

&lt;h3 id=&quot;2-multi-head-attention&quot;&gt;2. Multi-Head Attention&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;MultiHead(Q, K, V) = Concat(head_1, \cdots, head_h) W^O \ \\\ where \ head_i = Attention(QW_i^Q, KW_i^K, VW_i^V)&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;$W_i^Q \in R_{d_{model} \times d_k}$&lt;/li&gt;
  &lt;li&gt;$W_i^K \in R_{d_{model} \times d_k}$&lt;/li&gt;
  &lt;li&gt;$W_i^V \in R_{d_{model} \times d_k}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;해당 연구에서는 multi head attention을 적용하였다. 이는 두 가지 방식으로 성능향상에 기여하였다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;model이 다른 위치에 집중할 수 있는 능력을 향상시켰다.  “The animal didn’t cross the street because it was too tired” 과 같은 문장을 번역하는데 효과적인데 그 이유는 it이 가르키는 것이 무엇인지 중요하기 때문이다.&lt;/li&gt;
  &lt;li&gt;layer multiple representation subspace를 제공한다. 복수의 Q, K, V matrix를 가지게 되고 이는 random하게 초기화된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;아래의 그림은 두 개의 embedding vector(Thinking, Machines)의 복수의 head를 가지게 되는 과정을 시각화 한 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://jalammar.github.io/images/t/transformer_self-attention_visualization_3.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;representing-the-order-of-the-sequence-using-positional-encoding&quot;&gt;Representing The Order of The Sequence Using Positional Encoding&lt;/h2&gt;

&lt;p&gt;위에서의 attention 과정에서 word의 위치정보를 잃어버리게 된다. 이를 어떻게 복구할 것인가?&lt;/p&gt;

&lt;p&gt;이런 문제를 극복하기 위해서 Transformer에서는 input embedding vector에 특별한 vector를 더한다.  이는 각 word의 위치를 파악하는데 도움을 주거나 각 word의 distance를 구하는데 도움을 줄 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://jalammar.github.io/images/t/transformer_positional_encoding_vectors.png&quot; style=&quot;width: 80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://jalammar.github.io/images/t/transformer_positional_encoding_example.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;아래의 이미지는 실제 20개의 word의 positional encoding의 시각화 결과이다. (512 dimension)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://jalammar.github.io/images/t/transformer_positional_encoding_large_example.png&quot; /&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;PE_{(pos, 2i)}=sin(pos/10000^{2i/d_{model}})&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;PE_{(pos, 2i+1)}=cos(pos/10000^{2i/d_{model}})&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;pos는 word의 위치를 나타낸다.&lt;/li&gt;
  &lt;li&gt;i 는 dimension의 index를 나타낸다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;reference&quot;&gt;Reference&lt;/h4&gt;

&lt;p&gt;http://jalammar.github.io/illustrated-transformer/&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Abstract</title><link href="https://rroundtable.github.io/FastPages/2019/11/04/Unsupervised-Monocular-Depth-Estimation-with-Left-Right-Consistency-%EC%A0%95%EB%A6%AC%EA%B8%80.html" rel="alternate" type="text/html" title="Abstract" /><published>2019-11-04T00:00:00-06:00</published><updated>2019-11-04T00:00:00-06:00</updated><id>https://rroundtable.github.io/FastPages/2019/11/04/Unsupervised-Monocular-Depth-Estimation-with-Left-Right-Consistency-%EC%A0%95%EB%A6%AC%EA%B8%80</id><content type="html" xml:base="https://rroundtable.github.io/FastPages/2019/11/04/Unsupervised-Monocular-Depth-Estimation-with-Left-Right-Consistency-%EC%A0%95%EB%A6%AC%EA%B8%80.html">&lt;p&gt;많은 방법론들이 depth estimation부분에서 성과를 보여주었다. 하지만,  대부분 지도학습이라는 한계를 가지고 있으며, 이는 결국 많은 수의 ground-truth data가 필요하다는 것을 의미한다. 하지만, depth를 기록하는 것은 매우 어려운 문제이다. 따라서 이 연구에서는 얻기 쉬운 binocular stereo footage를 이용하여 문제를 해결한다.&lt;/p&gt;

&lt;p&gt;epipolar geometry constraints를 활용해서 reconstruction loss로 학습을 시킬 수 있다. 하지만 이 결과물은 depth image의 질이 낮아진다. 이러한 문제를 해결하기 위해서,  consistency를 유지할 수 있게하는 loss를 제안한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Epipolar geometry&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/7/7c/Aufnahme_mit_zwei_Kameras.svg/250px-Aufnahme_mit_zwei_Kameras.svg.png&quot; /&gt;&lt;/p&gt;

  &lt;p&gt;stereo vision의 geometry,&lt;/p&gt;

  &lt;p&gt;2개의 각기 다른 위치에서 3D 이미지의 정보를 얻을 때. 3D points와 2D points간의 많은 기하학적 관계가 있다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;이전의 많은 연구들이 multiple observation이 가능하다는 가정아래에서 진행되었다. multiple viewpoint와 다른 조명조건에서의 data도 필요하다. 이러한 한계를 극복하기 위해서, supervised learning방식으로 mono depth estimation 방법론들이 연구되었다. 이러한 방법론들은 많은 수의 data를 기반으로 depth를 직접적으로 추정하고자 하였다. 많은 성과를 이루었지만, 데이터의 수가 많아야된다는 한계를 가지고 있다.(depth 관련 데이터를 수집하기는 힘들다)&lt;/p&gt;

&lt;p&gt;image의 외관과 관계없이 장면의 모양을 이해할 수 있는 것은 machine perception분야에서 매우 중요한 이슈이다.&lt;/p&gt;

&lt;p&gt;사람은 monocular depth estimation을 잘하는데 이를 위해서 다음과 같은 힌트를 사용한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;원근법&lt;/li&gt;
  &lt;li&gt;이미 알려진 물체크기로 상대적인 추정&lt;/li&gt;
  &lt;li&gt;조명 혹은 그림자 가려진 상태에서의 모양&lt;/li&gt;
  &lt;li&gt;etc&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;위와 같은 top-down, bottom-up 힌트들을 조합해서 정확하게 depth를 추정할 수 있다. 이 연구에서는 depth data가 필요하지 않다. 학습과정에서는 synthesize depth를 이용한다.  두 이미지(left view, right view) 사이에서 해당 모델은 pixel level의 예측을 한다. (regression) 다른 연구에서도 이와 같은 방법론을 사용했지만 아래와 같은 한계가 존재한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;memory issue&lt;/li&gt;
  &lt;li&gt;not fully diferentiable&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;related-work&quot;&gt;Related Work&lt;/h2&gt;

&lt;h3 id=&quot;learning-based-stereo-between-two-images&quot;&gt;Learning-Based Stereo: between two images&lt;/h3&gt;

&lt;p&gt;대게 stereo estimation은 첫번째 이미지의 특정 픽셀과 두번째 이미지의 모든 pixel간의 similarity를 계산하는 알고리즘이다. 대부분의 stereo pairs는 정제되어 있으며, disparity estimation은 각 pixel의 1D search 문제이다.&lt;/p&gt;

&lt;p&gt;하지만, 최근 연구에 따르면,  head defined similarity measure방법론보다 matching function을 일종의 supervised learning problem으로 두고 문제를 해결하는 것이 더 좋은 성능을 보였다. 특히 Mayer et al.fully convolutional deep network를 활용하여 DispNet을 고안하였다.  이 방법론은 매우 많은 수의 ground-truth data가 필요했다.&lt;/p&gt;

&lt;h3 id=&quot;supervised-single-image-depth-estimation&quot;&gt;Supervised Single Image Depth Estimation&lt;/h3&gt;

&lt;p&gt;Saxena et al. patch based model(&lt;a href=&quot;http://make3d.cs.cornell.edu/&quot;&gt;Make3D&lt;/a&gt;)을 제안하였다. 이는 laser scan data를 이용하여 학습되었으며 prediction은 MRF를 활용하여 결합하였다. 이 방법론의 단점은 얇은 구조물을 modeling하는데 적절하지 않았다. 이는 현실적인 이미지를 만드는데 적절치 않다는 것을 의미한다.&lt;/p&gt;

&lt;p&gt;위의 방법론은 hand tuning이 필요하다. 이런 방법론과 다르게, Liu et al은 CNN을 이용하여 이를 학습하고자 했다.&lt;/p&gt;

&lt;p&gt;Karsch et al. consistent한 image output을 가질려고 노력했다. 이는 training set으로부터 depth image를 복사하여 이루어졌다. 따라서 이 방법론은 test할 때, 모든 training set이 필요하다는 한계를 가진다.&lt;/p&gt;

&lt;p&gt;Eigen et al.은 두개의 scale deep network를 활용해서 depth estimation이 가능하다는 것을 보였다. 이들은 hand craft feature를 사용하지 않았고, initial over segmentation을 이용하지 않았다. 대신에 raw pixel value를 활용하여, representation을 하였다.&lt;/p&gt;

&lt;p&gt;많은 연구들이 CRF기반으로 accuracy향상을 이루었다.&lt;/p&gt;

&lt;h3 id=&quot;unsupervised-depth-estimation&quot;&gt;Unsupervised Depth Estimation&lt;/h3&gt;

&lt;p&gt;Flynne et al.의 DeepStereo는 새로운 view의 이미지를 만들어낸다. 학습하는동안,  다양한 카메라의 상대적인 pose가 근처 이미지의 모습을 만들어내는데 사용된다. test할 때, image synthesis는 겹치는 작은 patch에서 작동한다. 이 모델은 근처의 다른 posed image의 view가 필요하므로,  monocular depth estimation에 부적절하다.&lt;/p&gt;

&lt;p&gt;Xie et al의 Deep3D의 목표는 left image 기반으로 right view이미지를 만들어내는 것이다. reconstruction loss를 활용하며,  각 픽셀에 대해서 가능한 disparities에 대해서 분포를 만들어낸다. 이 방법론의 단점은 scalable하지 않다는 것이다. 가능한 disparities가 많아질수록 많은 memory가 필요하다.&lt;/p&gt;

&lt;p&gt;해당연구와 비슷한 연구는 Garg et al이 제안하였다. 이 nework는 monocular depth estimation방법론이긴 하지만, fully differentiable하지 않다는 한계를 가진다. 이런 점을 극복하기 위해서 taylor approximation을 사용하였다.&lt;/p&gt;

&lt;h2 id=&quot;method&quot;&gt;Method&lt;/h2&gt;

&lt;h3 id=&quot;1-depth-estimation-as-image-reconstruction&quot;&gt;1. Depth Estimation as Image Reconstruction&lt;/h3&gt;

&lt;p&gt;해당 연구에서는 직접 depth를 추정하는 것이 아니라 image reconstruction을 이용하여 추정한다. 기존의 연구에서는 depth estimation문제를 supervised task로 인식해서 해결했지만, 앞서 설명했듯이 depth ground truth data를 구하는 것은 매우 힘든 일이다. 비싼 하드웨어를 사용하더라고 실제환경에서는 정확하지 않을 수 있다.&lt;/p&gt;

&lt;p&gt;이 연구에서는 training과정에서 image reconstruction을 활용하여 해결한다. 메인 아이디어는 left-view image에서 right-view image를 만들 수 있는function을 구할 수 있다면, 3D shape에 대한 지식을 알고 있는 것이라고 볼 수 있다.(right view -&amp;gt; left-view도 마찬가지)&lt;/p&gt;

&lt;p&gt;left-view image로부터 right-view image를 만든다음에 각 픽셀이 가지는 depth value를 추정한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Image disparity&lt;/p&gt;

  &lt;p&gt;https://www.quora.com/What-are-disparity-maps-and-How-are-they-created&lt;/p&gt;

  &lt;ul&gt;
    &lt;li&gt;baseline distance between the camera and the camera focal length $f$: $b$&lt;/li&gt;
    &lt;li&gt;image disparity: $d$&lt;/li&gt;
    &lt;li&gt;depth $\hat{d} = bf/d$&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;2--depth-estimation-network&quot;&gt;2.  Depth Estimation Network&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;Disparity map&lt;/p&gt;

  &lt;p&gt;&lt;img src=&quot;https://i.stack.imgur.com/tECoA.png&quot; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 연구에서는 left-to-right , right-to-left disparities를 모두 구할 수 있으며, 서로 consistency를 유지하게 함으로써 더 좋은 성능을 가져온다.  아래는 기존의 연구의 architecture와 해당 연구의 architecture를 보여주고 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/27891090/68211370-c6a3e180-001a-11ea-944e-c70cf85c7cad.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;오른쪽 이미지를 보면, left image를 가지고 right image를 생성해낸다. 하지만, 우리는 right-view image에서 sampling된 left-view image가 필요하다.  No LR을 보면 right-view image에서 left view image를 생성한다. 하지만 이는 texture-copy artifact라는 현상을 보이며, detph가 연속적이지 않은 부분에서 error가 많이 발생한다. 아래의 이미지를 보면 알 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/27891090/68212304-9bba8d00-001c-11ea-8cb0-9753fca7f09a.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 연구에서는 이 문제를 model이 두가지 disparity map를 생성해내도록 만들어서 해결하였다. (sampling from the opposite input images) 이 방법은 여전히 left-view image하나만 필요하며, right image는 training과정에서만 사용된다. left-right consistency loss를 이용하여, 더 정확한 정확도를 가질 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;3-training-loss&quot;&gt;3. Training Loss&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;C = \Sigma_{s=1}^4C_s&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;C_{s} = \alpha_{ap}(C_{ap}^l + C_{ap}^r) + \alpha_{ds}(C_{ds}^l + C_{ds}^r) + \alpha_{lr}(C_{lr}^l + C_{lr}^r)&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Apperance Matching Loss: $C_{ap}$&lt;/li&gt;
  &lt;li&gt;Disparity Smoothness Loss: $C_{ds}$&lt;/li&gt;
  &lt;li&gt;Left-Right Disparity Consistency: $C_{lr}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/27891090/68212839-b6413600-001d-11ea-89cf-2e89ac8071a2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Apperance Matching Loss&lt;/strong&gt;는 oposite setero이미지로부터 image를 생성하도록 학습시킨다. 여기서는 spatial transformer network를 사용하여 disparity map을 만든다. 여기서 bilinear sampler를 사용하는데 locally fully differentiable하며 fully convolutional architecture를 가진다.&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;C_{ap}^l = \frac{1}{N}\Sigma_{i, j}\alpha\frac{1 -SSIM(I_{ij}^l, \hat{I}_{i,j}^l)}{2} + (1 - \alpha)\rVert I_{ij}^l - \hat{I}_{i,j}^l \rVert&lt;/script&gt;
이 연구에서는 $\alpha$ 는 0.85 SSIMd에서는 3 x 3 block filter를 사용했다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;SSIM: structural similarity&lt;/p&gt;

  &lt;p&gt;사람의 시각 시스템은 이미지에서 구조 정보를 도출하는데 특화되어 있기 때문에 구조 정보의 왜곡정도가 지각 품질에 가장 큰 영향을 미친다. 이것이 SSIM의 기본이 되는 핵심가설이다. 구체적으로는 원본 이미지 x와 왜곡 이미지 y의 brightness, contrast, structure를 비교한다.&lt;/p&gt;

  &lt;ul&gt;
    &lt;li&gt;
      &lt;p&gt;brightness&lt;/p&gt;

      &lt;p&gt;$u_x$: x 이미지의 평균밝기&lt;/p&gt;

      &lt;p&gt;$u_y$: y 이미지의 평균 밝기&lt;/p&gt;

      &lt;p&gt;$I(x, y) = \frac{2u_xu_y + C_1}{u_x^2 + u_y^2 + C_2}$&lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
      &lt;p&gt;contrast&lt;/p&gt;

      &lt;p&gt;$C(x, y) = \frac{2\sigma_x\sigma_y+C_2}{\sigma_x^2 + \sigma_y^2 + C_2}$&lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
      &lt;p&gt;structure&lt;/p&gt;

      &lt;p&gt;structure = $\frac{x-u_x}{\sigma_x}$&lt;/p&gt;

      &lt;p&gt;$S(x, y) = \frac{\sigma_{xy} + C_3}{\sigma_x\sigma_y + C_3}$&lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
      &lt;p&gt;SSIM&lt;/p&gt;

      &lt;p&gt;$SSIM(x,y) = I(x,y)C(c,y)S(x,y)$&lt;/p&gt;

      &lt;p&gt;$SSIM(x, y)= \frac{(2u_xu_y + C_1) (2\sigma_{xy} +C_2)}{(u_x^2 + u_y^2 + C_1)(\sigma_x^2 + \sigma_y^2 +C_2)}$&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Disparity Smoothness Loss&lt;/strong&gt;의 경우에는 아래와 같이 수식으로 표현된다. 이는 disparities가 locally smooth하게 하는 효과를 가져온다.
&lt;script type=&quot;math/tex&quot;&gt;D_{ds}^l = \frac{1}{N}\Sigma_{i,j}\rvert \partial_{x}d_{i,j}^l\rvert e ^{\rVert \partial_{x}I_{i,j}\rVert} + \rvert \partial_y d_{i,j}^l \rvert e ^{\rVert\partial_y I_{i,j}\rVert}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Left-Right Disparity Consistency Loss&lt;/strong&gt; 는 더 정확한 disparity map을 만들기 위한 term이다.  이 term은 left-view disparity map을 projected right-view disparity map과 동일하게 만들어주는 역할을 한다.
&lt;script type=&quot;math/tex&quot;&gt;C_{lr} ^l = \frac{1}{N}\Sigma_{i,j}\rvert d_{ij}^l - d_{ij+d_{ij}^l} ^r \rvert&lt;/script&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">많은 방법론들이 depth estimation부분에서 성과를 보여주었다. 하지만, 대부분 지도학습이라는 한계를 가지고 있으며, 이는 결국 많은 수의 ground-truth data가 필요하다는 것을 의미한다. 하지만, depth를 기록하는 것은 매우 어려운 문제이다. 따라서 이 연구에서는 얻기 쉬운 binocular stereo footage를 이용하여 문제를 해결한다.</summary></entry><entry><title type="html">Introduction</title><link href="https://rroundtable.github.io/FastPages/2019/10/29/Feature-Visulatization-%EB%B2%88%EC%97%AD%EA%B8%80.html" rel="alternate" type="text/html" title="Introduction" /><published>2019-10-29T00:00:00-05:00</published><updated>2019-10-29T00:00:00-05:00</updated><id>https://rroundtable.github.io/FastPages/2019/10/29/Feature-Visulatization-%EB%B2%88%EC%97%AD%EA%B8%80</id><content type="html" xml:base="https://rroundtable.github.io/FastPages/2019/10/29/Feature-Visulatization-%EB%B2%88%EC%97%AD%EA%B8%80.html">&lt;p&gt;neural network의 해석가능성에 대한 필요성이 늘어나고 있다. Deep learning의 해석가능성은 크게 두 가지 문제로 나뉜다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;feature visualization&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/27891090/67741701-62eb4880-fa5d-11e9-84d4-f92d023cab58.png&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;network 혹은 network의 부분이 무엇을 보고자 하는가&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;attribution&lt;/p&gt;

    &lt;p&gt;network가 다음과 같이 동작하는 이유가 무엇인가&lt;/p&gt;

    &lt;p&gt;class activation map이 하나의 예시가 될 수 있다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;feature-visualization-by-optimization&quot;&gt;Feature Visualization by Optimization&lt;/h2&gt;

&lt;p&gt;일반적으로 neural network는 input에 대해서 differentiable하다. 만약 당신이 어떤 종류의 input이 특정한 행동양상을 가지는지 알고 싶다면(내부적인 뉴런의 동작 혹은 마지막 결과물의 양상이 예시가 될 수 있다.),  iteratively 미분하면서 목표를 이룰수 있다. 이렇게 얘기하면 매우 쉬울 거 같지만, 이를 하기 위해서는 많은 문제를 해결해야 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/27891090/67742020-2704b300-fa5e-11e9-9953-6a0b01ec647d.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 예시는 random noise를 input으로 두고 특정 뉴런을 활성화 시키기 위해서 input을 변화시켜나가는 과정으로 보인다.&lt;/p&gt;

&lt;h3 id=&quot;optimization-objective&quot;&gt;Optimization Objective&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/27891090/67742810-53b9ca00-fa60-11e9-8c7a-e9b3b50d2952.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Neuron: $layer_n [x,y,z]$&lt;/li&gt;
  &lt;li&gt;Channel: $layer_n[:, :, z]$&lt;/li&gt;
  &lt;li&gt;Layer: $layer_n[:,:,:]$&lt;/li&gt;
  &lt;li&gt;Class Logit:pre_softmax[k]&lt;/li&gt;
  &lt;li&gt;Class Probability: softmax[k]&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;주목할 점은 특정 class의 softmax 값을 증가시키는 쉬운 방법은 해당 class에 가깝게 만드는 것이 아니라, 다른 class과 유사하지 않게 만드는 식으로 optimization이 진행된다는 것이다. 경험상 class logit을 objective로 삼는 것이 더 좋은 결과를 얻을 수 있었다.&lt;/p&gt;

&lt;p&gt;위의 방법론 말고도 여러가지 방법을 시도해 볼 수 있다.  style transfer도 좋은 예시이다. style transfer에서는 content와 style이라는 개념이 나온다. model이 optimization을 진행할 때 어떤 정보는 유지하고 어떤 정보는 버리는지에 대해서 알 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;why-visualize-by-optimization&quot;&gt;Why visualize by optimization?&lt;/h3&gt;

&lt;p&gt;왜 dataset 그 자체로는 feature visualization을 하지 않고 optimization을 사용하는가?&lt;/p&gt;

&lt;p&gt;이는 optimization이 model이 실제로 보고 있는 것을 시각화 할 수 있는 효과적인 방법이기 때문이다. 실제 dataset은 neuron이 보고 있는 것과 차이가 생길 수 있다.&lt;/p&gt;

&lt;p&gt;그 이유는 optimization이 model의 행동을 유발하는 요소와 상관관계가 있는 요소를 분리할 수 있기 때문이다.  아래의 예시 이미지를 보면 쉽게 알 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/27891090/67744171-1fe0a380-fa64-11e9-8563-4ebf5d4f44ec.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;또한 optimization은 유연하다는 장점을 가진다. 특정 neuron을 활성화 시키고 싶다면 그에 맞게 수식을 적용하면 된다.&lt;/p&gt;

&lt;h2 id=&quot;diversity&quot;&gt;Diversity&lt;/h2&gt;

&lt;p&gt;optimization을 사용할 때는 주의할 필요가 있다.예를 들어,  genuine을 표현하고 싶은데, facet의 특징으로 설명할 수 도 있다.&lt;/p&gt;

&lt;p&gt;여기서 Dataset example이 매우 큰 장점을 가진다. 이를 통해서 diverse example을 찾을 수 있었다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/27891090/67744675-887c5000-fa65-11e9-8e4e-c893331ff385.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;achieving-diversity-with-optimization&quot;&gt;Achieving Diversity with Optimization&lt;/h3&gt;

&lt;p&gt;nework는 inputs의 넓은 범위에 활성화될 수 있다. 예를 들어서 class level에서 생각해보자. 만약 classifier가 개를 인식하게 학습이 되었다면, 해당 classifier는 개의 얼굴과 전체적인 시각적인 특징을 잡아내야 한다. (비록 시각적으로 그 둘의 차이가 크더라도)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;related work&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이전의 연구에서 intra-class diversity에 대해서 밝히려는 시도가 있었다. &lt;a href=&quot;https://arxiv.org/pdf/1507.02379.pdf&quot;&gt;[1]&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;training set에서 나오는 모든 activation을 수집해서 clustering을 하였다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;다른 방식으로 접근한 예도 있다. &lt;a href=&quot;https://arxiv.org/pdf/1602.03616.pdf&quot;&gt;[2]&lt;/a&gt; 이 방법은 optimization process의 staring point를 가지고 intra class diversity를 증명하려고 했다.&lt;/p&gt;

&lt;p&gt;최근의 연구로는 generative model과 결합한 시도가 있다&lt;a href=&quot;https://arxiv.org/pdf/1612.00005.pdf&quot;&gt;[3]&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;이 글에서 제시하는 방법은 간단하게 적용할 수 있다. diversity term을 objective에 추가해서 multiple example이 서로 다르다고 하게끔 학습이 진행된다. 결과가 개선되었는데 정확한 이유는 아직 알 수 없다. 다만 추측하기로는 penalize the cosine similarity 혹은 feature가 다른 style로 보일 수 있게끔 학습이 진행되어서 그런것이라고 보고 있다.(style transfer)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/27891090/67851761-75917a80-fb4e-11e9-942c-babc277684a6.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;오른쪽을 보면 다양한 뷰의 강아진 사진이있다. 그리고 왼쪽의 결과물은 diversity를 고려한 optimization의 결과물이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://distill.pub/2017/feature-visualization/images/diversity/mixed4a_143_optimized.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 그림은 diversity를 고려하지 않은 결과물이다.&lt;/p&gt;

&lt;h2 id=&quot;interaction-between-neurons&quot;&gt;Interaction between Neurons&lt;/h2&gt;

&lt;p&gt;neuron은 혼자서 작용하는 것이 아니라 다른 neuron과의 상호작용을 통해서 결과물을 도출한다. 이를 이해하기 위해서 geometrically하게 생각하는 것을 추천한다.&lt;/p&gt;

&lt;p&gt;activation space를  activation의 모든 조합이 나올 수 있는 공간이라고 정의하자. 그렇다면 우리는 activation자체를 basis로 생각할 수 있다. 그리고 activation의 조합은 activation space에서 vector의 역할을 한다.&lt;/p&gt;

&lt;p&gt;위에서 언급한 activaiton space, combination of activation, vector는  basis vector가 다른 vector에 비해서 더 해석하기 쉬울까에 대해서 논의할 수 있다.&lt;/p&gt;

&lt;p&gt;이전의 연구에서 basis vector의 direction이 더 쉽게 이해할 수 있다고 한다. &lt;a href=&quot;https://arxiv.org/pdf/1312.6199.pdf&quot;&gt;[1]&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/pdf/1704.05796.pdf&quot;&gt;[2]&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;그리고 이글에서의 실험도 위의 견해와 일치하게 결과가 나왔다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/27891090/67852505-dff6ea80-fb4f-11e9-8b6e-188c98c3ea79.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 이미지는 각 이미지에 대한 optimization을 적용하였을 때의 결과물이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/27891090/67854508-cfe10a00-fb53-11e9-8c33-146c7b0a7aee.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 결과물도 흥미롭다. direction을 정의할 수 있다는 것인데, mosaic neuron에 흑백의 neruon을 더하면 흑백의 mosaic neuron이 나오게 된다. 이는 word2vector 혹은 generative model의 latent space와 유사한 개념이다.&lt;/p&gt;

&lt;p&gt;(interpolation)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/27891090/67854832-6e6d6b00-fb54-11e9-8390-05fa0ece1da9.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 이미지는  두 뉴런의 interpolation의 결과물이다. 해당 뉴런이 어떤식으로 결합되는지 확인할 수 있다. 위의 방법으로는 아주 작은 힌트만 얻을 수 있다. 예를 들면, 몇개의 interaction이 존재하는지 하지만 실제상황에서는 수백개의 interaction이 존재한다.&lt;/p&gt;

&lt;h2 id=&quot;the-enemy-of-feature-visualization&quot;&gt;The Enemy of Feature Visualization&lt;/h2&gt;

&lt;p&gt;위에서 말한 optimization 방법론은 실제로 잘 작동하지 않는다. 아래 이미지와 같은 약간 이상하면서 자주 나타나는 패턴이 있다. 이 이미지는 실제 data상에서 잘 보이지 않는 패턴이며, 특정 뉴런을 활성화 시키기 위한 cheeting 같은 느낌이 든다. 이는 adversarial attack과 유사해보인다&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/27891090/68006959-93c9b880-fcbd-11e9-91fc-2b1f1e197832.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위에서 언급한 자주 보이는 패턴이 convolution과 pooling 연산에 의존적임을 확인할 수 있었다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/27891090/68007106-f15e0500-fcbd-11e9-89d0-52a72fb2e46b.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;정리하자면, constraint없는 optimization은 매력적이긴 하지만, 위의 예시처럼 의미없는 결과를 불러올 수 있다. (결국 adversarial example과 유사하게 만들어진다.)&lt;/p&gt;

&lt;h3 id=&quot;the-spectrum-of-regularization&quot;&gt;The Spectrum of Regularization&lt;/h3&gt;

&lt;p&gt;위의 자주 보이는 패턴을 다루는 것은 feature visualization 연구에서 매우 중요한 영역이다. 만약 더 유용한 visualization을 원한다면, prior, regularizer, constraint를 조합하여 만들어야한다.&lt;/p&gt;

&lt;p&gt;연구분야에서는 regularization에 대한 관심이 많아보인다.&lt;/p&gt;

&lt;h4 id=&quot;reference&quot;&gt;Reference&lt;/h4&gt;

&lt;p&gt;https://distill.pub/2017/feature-visualization/&lt;/p&gt;</content><author><name></name></author><summary type="html">neural network의 해석가능성에 대한 필요성이 늘어나고 있다. Deep learning의 해석가능성은 크게 두 가지 문제로 나뉜다.</summary></entry></feed>